{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60df5758-c195-4bc6-be70-227f0581c155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-23 08:09:17.563815: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-23 08:09:17.564288: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-23 08:09:17.566422: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-23 08:09:17.572324: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737630557.582345 2948706 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737630557.585151 2948706 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-23 08:09:17.595471: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.models import load_model #save and load models\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import average_precision_score\n",
    "import tensorflow.keras.backend as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc43f385-3df2-4853-9b88-eeec34f84853",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/adult.data',  names=[\n",
    "        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n",
    "        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n",
    "        \"Hours per week\", \"Country\", \"Target\"],\n",
    "        sep=r'\\s*,\\s*',\n",
    "        engine='python',\n",
    "        na_values=\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59b12e9c-2d88-44f6-8d17-d5d7e1a5094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"data/adult.test\",\n",
    "    names=[\n",
    "        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n",
    "        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n",
    "        \"Hours per week\", \"Country\", \"Target\"],\n",
    "        sep=r'\\s*,\\s*',\n",
    "        engine='python',\\\n",
    "        na_values=\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72fd2207-f1c6-49f5-b939-d2736f7b9961",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df, df1], ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "372ed544-6249-4094-b015-2dfbe51c8428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Workclass', 'fnlwgt', 'Education', 'Education-Num', 'Martial Status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Capital Gain', 'Capital Loss', 'Hours per week', 'Country', 'Target']\n",
      "(48842, 15)\n"
     ]
    }
   ],
   "source": [
    "names_cloud = data.columns.tolist()\n",
    "print(names_cloud)\n",
    "X = np.array(data[names_cloud])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0024503-c2ae-4891-90c4-dc9e6ef2d572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    37155\n",
      "1    11687\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2948706/3481380141.py:2: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  print(pd.value_counts(pd.Series(y)))\n"
     ]
    }
   ],
   "source": [
    "y = (data['Target'].map({\"<=50K\":0,\">50K\":1})).values\n",
    "print(pd.value_counts(pd.Series(y)))\n",
    "data.drop('Target',axis=1, inplace =True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3be575b-996b-4106-b94f-5aedc08850fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Workclass', 'Education', 'Martial Status', 'Occupation',\n",
      "       'Relationship', 'Race', 'Sex', 'Country'],\n",
      "      dtype='object')\n",
      "(48842, 105)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education-Num</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Hours per week</th>\n",
       "      <th>Workclass_Federal-gov</th>\n",
       "      <th>Workclass_Local-gov</th>\n",
       "      <th>Workclass_Never-worked</th>\n",
       "      <th>Workclass_Private</th>\n",
       "      <th>...</th>\n",
       "      <th>Country_Portugal</th>\n",
       "      <th>Country_Puerto-Rico</th>\n",
       "      <th>Country_Scotland</th>\n",
       "      <th>Country_South</th>\n",
       "      <th>Country_Taiwan</th>\n",
       "      <th>Country_Thailand</th>\n",
       "      <th>Country_Trinadad&amp;Tobago</th>\n",
       "      <th>Country_United-States</th>\n",
       "      <th>Country_Vietnam</th>\n",
       "      <th>Country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  fnlwgt  Education-Num  Capital Gain  Capital Loss  Hours per week  \\\n",
       "0   39   77516             13          2174             0              40   \n",
       "1   50   83311             13             0             0              13   \n",
       "2   38  215646              9             0             0              40   \n",
       "3   53  234721              7             0             0              40   \n",
       "4   28  338409             13             0             0              40   \n",
       "\n",
       "   Workclass_Federal-gov  Workclass_Local-gov  Workclass_Never-worked  \\\n",
       "0                  False                False                   False   \n",
       "1                  False                False                   False   \n",
       "2                  False                False                   False   \n",
       "3                  False                False                   False   \n",
       "4                  False                False                   False   \n",
       "\n",
       "   Workclass_Private  ...  Country_Portugal  Country_Puerto-Rico  \\\n",
       "0              False  ...             False                False   \n",
       "1              False  ...             False                False   \n",
       "2               True  ...             False                False   \n",
       "3               True  ...             False                False   \n",
       "4               True  ...             False                False   \n",
       "\n",
       "   Country_Scotland  Country_South  Country_Taiwan  Country_Thailand  \\\n",
       "0             False          False           False             False   \n",
       "1             False          False           False             False   \n",
       "2             False          False           False             False   \n",
       "3             False          False           False             False   \n",
       "4             False          False           False             False   \n",
       "\n",
       "   Country_Trinadad&Tobago  Country_United-States  Country_Vietnam  \\\n",
       "0                    False                   True            False   \n",
       "1                    False                   True            False   \n",
       "2                    False                   True            False   \n",
       "3                    False                   True            False   \n",
       "4                    False                  False            False   \n",
       "\n",
       "   Country_Yugoslavia  \n",
       "0               False  \n",
       "1               False  \n",
       "2               False  \n",
       "3               False  \n",
       "4               False  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = data.select_dtypes(include=['object']).columns\n",
    "print(categorical_features)\n",
    "ohc_category = ['Workclass', 'Education', 'Martial Status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Country']\n",
    "df_ohc = pd.get_dummies(data, columns = ohc_category)\n",
    "print(df_ohc.shape)\n",
    "df_ohc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c48cd5c-d7f2-424f-9d71-359170c47250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Variable: Target\n",
      "Predictors: ['Age', 'fnlwgt', 'Education-Num', 'Capital Gain', 'Capital Loss', 'Hours per week', 'Workclass_Federal-gov', 'Workclass_Local-gov', 'Workclass_Never-worked', 'Workclass_Private', 'Workclass_Self-emp-inc', 'Workclass_Self-emp-not-inc', 'Workclass_State-gov', 'Workclass_Without-pay', 'Education_10th', 'Education_11th', 'Education_12th', 'Education_1st-4th', 'Education_5th-6th', 'Education_7th-8th', 'Education_9th', 'Education_Assoc-acdm', 'Education_Assoc-voc', 'Education_Bachelors', 'Education_Doctorate', 'Education_HS-grad', 'Education_Masters', 'Education_Preschool', 'Education_Prof-school', 'Education_Some-college', 'Martial Status_Divorced', 'Martial Status_Married-AF-spouse', 'Martial Status_Married-civ-spouse', 'Martial Status_Married-spouse-absent', 'Martial Status_Never-married', 'Martial Status_Separated', 'Martial Status_Widowed', 'Occupation_Adm-clerical', 'Occupation_Armed-Forces', 'Occupation_Craft-repair', 'Occupation_Exec-managerial', 'Occupation_Farming-fishing', 'Occupation_Handlers-cleaners', 'Occupation_Machine-op-inspct', 'Occupation_Other-service', 'Occupation_Priv-house-serv', 'Occupation_Prof-specialty', 'Occupation_Protective-serv', 'Occupation_Sales', 'Occupation_Tech-support', 'Occupation_Transport-moving', 'Relationship_Husband', 'Relationship_Not-in-family', 'Relationship_Other-relative', 'Relationship_Own-child', 'Relationship_Unmarried', 'Relationship_Wife', 'Race_Amer-Indian-Eskimo', 'Race_Asian-Pac-Islander', 'Race_Black', 'Race_Other', 'Race_White', 'Sex_Female', 'Sex_Male', 'Country_Cambodia', 'Country_Canada', 'Country_China', 'Country_Columbia', 'Country_Cuba', 'Country_Dominican-Republic', 'Country_Ecuador', 'Country_El-Salvador', 'Country_England', 'Country_France', 'Country_Germany', 'Country_Greece', 'Country_Guatemala', 'Country_Haiti', 'Country_Holand-Netherlands', 'Country_Honduras', 'Country_Hong', 'Country_Hungary', 'Country_India', 'Country_Iran', 'Country_Ireland', 'Country_Italy', 'Country_Jamaica', 'Country_Japan', 'Country_Laos', 'Country_Mexico', 'Country_Nicaragua', 'Country_Outlying-US(Guam-USVI-etc)', 'Country_Peru', 'Country_Philippines', 'Country_Poland', 'Country_Portugal', 'Country_Puerto-Rico', 'Country_Scotland', 'Country_South', 'Country_Taiwan', 'Country_Thailand', 'Country_Trinadad&Tobago', 'Country_United-States', 'Country_Vietnam', 'Country_Yugoslavia']\n",
      "Number of data samples : 48842\n",
      "Number of Predictor Features : 105\n"
     ]
    }
   ],
   "source": [
    "names_x = df_ohc.columns.tolist()\n",
    "print(\"Target Variable: Target\")\n",
    "print(\"Predictors: \"+str(names_x))\n",
    "x = np.array(df_ohc[names_x])\n",
    "print(\"Number of data samples : {0:d}\".format(x.shape[0]))\n",
    "print(\"Number of Predictor Features : {0:d}\".format(x.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca940dcc-20b0-4273-abf8-d49bd660d8f2",
   "metadata": {},
   "source": [
    "## MOdelo Alvo ORiginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9316ac46-520d-4249-8633-36b0244a6031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23509 38928 23796 ...   919 38467 10742]\n"
     ]
    }
   ],
   "source": [
    "x = x.astype('float32')\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "\n",
    "data_size = 10000\n",
    "ns = 5 #number of shadow models for one data_size\n",
    "\n",
    "nout = 1\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "sh = np.arange(x.shape[0])\n",
    "np.random.shuffle(sh)\n",
    "target_rep = np.zeros((1,x.shape[0]))\n",
    "target_rep[0,:] = sh\n",
    "print(sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "106f49bf-ecf7-4d8b-8acb-ff5d265b9093",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/emanuel/sdd_sata/projetos/projeto_mestrado_ofc/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "W0000 00:00:1737631089.961737 2948706 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/media/emanuel/sdd_sata/projetos/projeto_mestrado_ofc/.venv/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">530</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m530\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">536</span> (2.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m536\u001b[0m (2.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">536</span> (2.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m536\u001b[0m (2.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "For target model with training datasize = 10000\n",
      "Training accuracy = 0.853300\n",
      "Validation accuracy = 0.849200\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276us/step\n"
     ]
    }
   ],
   "source": [
    "k.clear_session()\n",
    "\n",
    "xtr_target = x[sh[:data_size]]\n",
    "ytr_target = y[sh[:data_size]]\n",
    "xts_target = x[sh[data_size:data_size*2]]\n",
    "yts_target = y[sh[data_size:2*data_size]]\n",
    "\n",
    "shadow_rep = np.zeros((5,x.shape[0]-2*data_size))\n",
    "sh1 = sh[2*data_size:]\n",
    "xtr_att = np.zeros((2*data_size*ns,1))\n",
    "ytr_att = np.zeros((2*data_size*ns,1))\n",
    "xtr_att_truelabels = np.zeros((2*data_size*ns,))\n",
    "\n",
    "model_target = Sequential()\n",
    "model_target.add(Dense(5, input_shape =(x.shape[1],), activation='sigmoid', name = 'hidden'))\n",
    "model_target.add(Dense(1, activation='sigmoid', name = 'output'))\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001, decay = 1e-7)\n",
    "model_target.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "print(model_target.summary())\n",
    "\n",
    "hist_target = model_target.fit(xtr_target, ytr_target,\n",
    "                  batch_size = 32,\n",
    "                  epochs = 100,\n",
    "                  validation_data=(xts_target, yts_target), shuffle=True, verbose=0)\n",
    "\n",
    "print('\\n\\nFor target model with training datasize = %d'%data_size)\n",
    "print('Training accuracy = %f'%hist_target.history['accuracy'][-1])\n",
    "print('Validation accuracy = %f'%hist_target.history['val_accuracy'][-1])\n",
    "\n",
    "model_target_name = 'UCI_Adult_target_'+str(data_size)+'.h5'\n",
    "\n",
    "model_target.save(model_target_name)\n",
    "\n",
    "ytemp_tr_target = model_target.predict(xtr_target)\n",
    "ytemp_ts_target = model_target.predict(xts_target)\n",
    "\n",
    "xts_att = np.vstack((ytemp_tr_target,ytemp_ts_target))\n",
    "yts_att = np.zeros((2*data_size,1))\n",
    "yts_att[data_size:2*data_size] = 1\n",
    "xts_att_truelabels = np.vstack((ytr_target,yts_target))\n",
    "xts_att_dict = {'xts_att':xts_att,'yts_att':yts_att,'xts_att_truelabels':xts_att_truelabels}\n",
    "\n",
    "fname = './att_test_data_'+str(data_size)\n",
    "np.save(fname,xts_att_dict)\n",
    "datafile = './data_adult_target_'+str(data_size)\n",
    "np.save(datafile,target_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c7de3c-4e23-4b2a-8f9c-88e962d64e04",
   "metadata": {},
   "source": [
    "## Modelo Sombra Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e5eabfd-0b94-487d-9d66-778fa65ec27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shadow Model Summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">530</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m530\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">536</span> (2.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m536\u001b[0m (2.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">536</span> (2.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m536\u001b[0m (2.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Shadow model no: 0\n",
      "\n",
      "\n",
      "For shadow model with training datasize = 10000\n",
      "Training accuracy = 0.855000\n",
      "Validation accuracy = 0.852800\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCI_Adult_shadow_10000_0.h5\n",
      "Shadow model no: 1\n",
      "\n",
      "\n",
      "For shadow model with training datasize = 10000\n",
      "Training accuracy = 0.858000\n",
      "Validation accuracy = 0.849800\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCI_Adult_shadow_10000_1.h5\n",
      "Shadow model no: 2\n",
      "\n",
      "\n",
      "For shadow model with training datasize = 10000\n",
      "Training accuracy = 0.860000\n",
      "Validation accuracy = 0.849200\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCI_Adult_shadow_10000_2.h5\n",
      "Shadow model no: 3\n",
      "\n",
      "\n",
      "For shadow model with training datasize = 10000\n",
      "Training accuracy = 0.863400\n",
      "Validation accuracy = 0.844800\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCI_Adult_shadow_10000_3.h5\n",
      "Shadow model no: 4\n",
      "\n",
      "\n",
      "For shadow model with training datasize = 10000\n",
      "Training accuracy = 0.857300\n",
      "Validation accuracy = 0.849200\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCI_Adult_shadow_10000_4.h5\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(ns):\n",
    "\n",
    "    np.random.shuffle(sh1)\n",
    "    shadow_rep[i,:] = sh1\n",
    "    \n",
    "    xtr_shadow = x[sh1[:data_size]]\n",
    "    ytr_shadow = y[sh1[:data_size]]\n",
    "    xts_shadow = x[sh1[data_size:2*data_size]]\n",
    "    yts_shadow = y[sh1[data_size:2*data_size]]\n",
    "\n",
    "    model_shadow = Sequential()\n",
    "    model_shadow.add(Dense(5, input_shape =(x.shape[1],), activation='sigmoid', name = 'hidden'))\n",
    "    model_shadow.add(Dense(1, activation='sigmoid', name = 'output'))\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001, decay=1e-7)\n",
    "    model_shadow.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    if i == 0:\n",
    "        print(\"Shadow Model Summary\")\n",
    "        print(model_shadow.summary())\n",
    "        \n",
    "    hist_shadow = model_shadow.fit(xtr_shadow, ytr_shadow,\n",
    "                  batch_size = 32,\n",
    "                  epochs = 100,\n",
    "                  validation_data=(xts_shadow, yts_shadow), shuffle=True, verbose=0)\n",
    "    \n",
    "    print(\"Shadow model no: %d\"%i)\n",
    "    print('\\n\\nFor shadow model with training datasize = %d'%data_size)\n",
    "    print('Training accuracy = %f'%hist_shadow.history['accuracy'][-1])\n",
    "    print('Validation accuracy = %f'%hist_shadow.history['val_accuracy'][-1])\n",
    "\n",
    "    ytemp11 = model_shadow.predict(xtr_shadow)\n",
    "    ytemp22 = model_shadow.predict(xts_shadow)\n",
    "\n",
    "    model_shadow_name = 'UCI_Adult_shadow_'+str(data_size)+'_'+str(i)+'.h5'\n",
    "    print(model_shadow_name)\n",
    "    model_shadow.save(model_shadow_name)\n",
    "\n",
    "    xtr_att[i*2*data_size:(i+1)*2*data_size] = np.vstack((ytemp11,ytemp22))\n",
    "    ytr_att[((i*2)+1)*data_size:(i+1)*2*data_size] = 1\n",
    "    xtr_att_truelabels[i*2*data_size:(i+1)*2*data_size] = np.hstack((ytr_shadow,yts_shadow))\n",
    "\n",
    "datafile = './data_adult_shadow_'+str(data_size)\n",
    "np.save(datafile,shadow_rep)\n",
    "xtr_att_dict = {'xtr_att':xtr_att,'ytr_att':ytr_att,'xtr_att_truelabels':xtr_att_truelabels}\n",
    "fname = './att_train_data_'+str(data_size)\n",
    "np.save(fname,xtr_att_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dc4a7d-68e1-470d-95b4-c66ff0e7a307",
   "metadata": {},
   "source": [
    "## Modelo de Ataque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6701995f-fd47-4fd3-b410-4ea539fa8216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Model Summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m10\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> (64.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16\u001b[0m (64.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> (64.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16\u001b[0m (64.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "\n",
      "For attack model with training datasize = 100000\n",
      "Training accuracy = 0.502200\n",
      "Validation accuracy = 0.500000\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253us/step\n",
      "Average precision-recall score: 0.50\n"
     ]
    }
   ],
   "source": [
    "model_attack = Sequential()\n",
    "model_attack.add(Dense(5, input_shape = (xtr_att.shape[1],), activation='sigmoid', name = 'hidden'))\n",
    "model_attack.add(Dense(1, activation='sigmoid', name = 'output'))\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001, decay=1e-7)\n",
    "\n",
    "model_attack.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "print(\"Attack Model Summary\")\n",
    "print(model_attack.summary())\n",
    "\n",
    "hist_attack = model_attack.fit(xtr_att, ytr_att,\n",
    "                  batch_size = 32,\n",
    "                  epochs = 100,\n",
    "                  validation_data=(xts_att, yts_att), shuffle=True, verbose=0)\n",
    "\n",
    "print('\\n\\nFor attack model with training datasize = %d'%xtr_att.shape[0])\n",
    "print('Training accuracy = %f'%hist_attack.history['accuracy'][-1])\n",
    "print('Validation accuracy = %f'%hist_attack.history['val_accuracy'][-1])\n",
    "\n",
    "y_score = model_attack.predict(xts_att)\n",
    "average_precision = average_precision_score(yts_att, y_score)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0288d5ae-151e-49de-8511-cb73673f99d4",
   "metadata": {},
   "source": [
    "## COmbinando amostras entre alvo e sombras no conjunto de teste do ataque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3254c448-0301-4052-a13c-89e4ad6cf365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268us/step\n",
      "\n",
      "\n",
      "For attack model with training datasize = 100000\n",
      "Training accuracy = 0.499410\n",
      "Validation accuracy = 0.500267\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step\n",
      "Average precision-recall score: 0.50\n"
     ]
    }
   ],
   "source": [
    "# # First, collect predictions from both target and shadow models for test set\n",
    "# # Assuming we want to use 20% of each shadow model's predictions in the test set\n",
    "\n",
    "# Calculate how many samples we want from each shadow model\n",
    "shadow_samples_per_model = int(0.2 * data_size)  # 20% of data_size\n",
    "total_shadow_samples = shadow_samples_per_model * ns  # ns is number of shadow models\n",
    "\n",
    "# Initialize arrays for combined test set\n",
    "xts_att_combined = np.zeros((2*data_size + total_shadow_samples, 1))\n",
    "yts_att_combined = np.zeros((2*data_size + total_shadow_samples, 1))\n",
    "xts_att_truelabels_combined = np.zeros((2*data_size + total_shadow_samples,))\n",
    "\n",
    "# First, add all target model predictions\n",
    "xts_att_combined[:2*data_size] = np.vstack((ytemp_tr_target, ytemp_ts_target))\n",
    "yts_att_combined[:data_size] = 0  # members (target train)\n",
    "yts_att_combined[data_size:2*data_size] = 1  # non-members (target test)\n",
    "xts_att_truelabels_combined[:2*data_size] = np.hstack((ytr_target, yts_target))\n",
    "\n",
    "# Then add portions of shadow model predictions\n",
    "current_index = 2*data_size\n",
    "\n",
    "for i in np.arange(ns):\n",
    "    # Load or get predictions from each shadow model\n",
    "    model_shadow = load_model(f'UCI_Adult_shadow_{data_size}_{i}.h5')\n",
    "\n",
    "    # Get predictions from shadow model\n",
    "    shadow_tr_preds = model_shadow.predict(xtr_shadow)  # predictions on shadow train data\n",
    "    shadow_ts_preds = model_shadow.predict(xts_shadow)  # predictions on shadow test data\n",
    "\n",
    "    # Randomly select samples from both train and test predictions\n",
    "    combined_preds = np.vstack((shadow_tr_preds, shadow_ts_preds))\n",
    "    combined_labels = np.hstack((np.zeros(data_size), np.ones(data_size)))  # 0 for members, 1 for non-members\n",
    "    combined_true_labels = np.hstack((ytr_shadow, yts_shadow))\n",
    "\n",
    "    # Randomly select indices\n",
    "    random_indices = np.random.choice(2*data_size, shadow_samples_per_model, replace=False)\n",
    "\n",
    "    # Add selected predictions and their labels to test set\n",
    "    end_index = current_index + shadow_samples_per_model\n",
    "    xts_att_combined[current_index:end_index] = combined_preds[random_indices].reshape(-1, 1)\n",
    "    yts_att_combined[current_index:end_index] = combined_labels[random_indices].reshape(-1, 1)\n",
    "    xts_att_truelabels_combined[current_index:end_index] = combined_true_labels[random_indices]\n",
    "\n",
    "    current_index = end_index\n",
    "\n",
    "# Save the combined test data\n",
    "xts_att_dict = {\n",
    "    'xts_att': xts_att_combined,\n",
    "    'yts_att': yts_att_combined,\n",
    "    'xts_att_truelabels': xts_att_truelabels_combined\n",
    "}\n",
    "fname = f'./att_test_data_combined_{data_size}'\n",
    "np.save(fname, xts_att_dict)\n",
    "\n",
    "\n",
    "hist_attack = model_attack.fit(xtr_att, ytr_att,\n",
    "                             batch_size=32,\n",
    "                             epochs=100,\n",
    "                             validation_data=(xts_att_combined, yts_att_combined),\n",
    "                             shuffle=True, verbose=0)\n",
    "\n",
    "\n",
    "print('\\n\\nFor attack model with training datasize = %d' % xtr_att.shape[0])\n",
    "print('Training accuracy = %f' % hist_attack.history['accuracy'][-1])\n",
    "print('Validation accuracy = %f' % hist_attack.history['val_accuracy'][-1])\n",
    "y_score = model_attack.predict(xts_att_combined)\n",
    "average_precision = average_precision_score(yts_att_combined, y_score)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78f29118-5c0f-4fa2-8e00-2c243dd25e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xts_att: 30000\n",
      "yts_att: 30000\n",
      "xts_att_truelabels: 30000\n"
     ]
    }
   ],
   "source": [
    "for key, value in xts_att_dict.items():\n",
    "  print(f'{key}: {len(value)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5527253e-dcd1-469a-a307-16fff3df7c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2948706/1860021247.py:7: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  'prediction': float(ytemp_tr_target[idx]),\n",
      "/tmp/ipykernel_2948706/1860021247.py:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  'prediction': float(ytemp_ts_target[idx]),\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2948706/1860021247.py:47: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  'prediction': float(shadow_tr_preds[idx]),\n",
      "/tmp/ipykernel_2948706/1860021247.py:58: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  'prediction': float(shadow_ts_preds[idx]),\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step\n",
      "\n",
      "Test Set Summary:\n",
      "\n",
      "Samples per model:\n",
      "model_name\n",
      "shadow_0     2000\n",
      "shadow_1     2000\n",
      "shadow_2     2000\n",
      "shadow_3     2000\n",
      "shadow_4     2000\n",
      "target      20000\n",
      "dtype: int64\n",
      "\n",
      "Member/Non-member distribution:\n",
      "is_member       0      1\n",
      "model_name              \n",
      "shadow_0     1000   1000\n",
      "shadow_1     1000   1000\n",
      "shadow_2     1000   1000\n",
      "shadow_3     1000   1000\n",
      "shadow_4     1000   1000\n",
      "target      10000  10000\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step\n",
      "\n",
      "Performance Analysis by Source:\n",
      "\n",
      "target:\n",
      "Accuracy: 0.498\n",
      "Correctly identified members: 7679\n",
      "Correctly identified non-members: 2285\n",
      "\n",
      "shadow_0:\n",
      "Accuracy: 0.487\n",
      "Correctly identified members: 735\n",
      "Correctly identified non-members: 239\n",
      "\n",
      "shadow_1:\n",
      "Accuracy: 0.491\n",
      "Correctly identified members: 759\n",
      "Correctly identified non-members: 224\n",
      "\n",
      "shadow_2:\n",
      "Accuracy: 0.500\n",
      "Correctly identified members: 790\n",
      "Correctly identified non-members: 210\n",
      "\n",
      "shadow_3:\n",
      "Accuracy: 0.504\n",
      "Correctly identified members: 783\n",
      "Correctly identified non-members: 225\n",
      "\n",
      "shadow_4:\n",
      "Accuracy: 0.509\n",
      "Correctly identified members: 774\n",
      "Correctly identified non-members: 244\n"
     ]
    }
   ],
   "source": [
    "# Create a structured array to store predictions and metadata\n",
    "test_set_data = []\n",
    "\n",
    "# Add target model predictions with metadata\n",
    "for idx in range(len(ytemp_tr_target)):\n",
    "    test_set_data.append({\n",
    "        'prediction': float(ytemp_tr_target[idx]),\n",
    "        'is_member': 0,  # member of training set\n",
    "        'true_label': int(ytr_target[idx]),\n",
    "        'model_name': 'target',\n",
    "        'sample_index': idx,\n",
    "        'data_split': 'train'\n",
    "    })\n",
    "\n",
    "for idx in range(len(ytemp_ts_target)):\n",
    "    test_set_data.append({\n",
    "        'prediction': float(ytemp_ts_target[idx]),\n",
    "        'is_member': 1,  # non-member (test set)\n",
    "        'true_label': int(yts_target[idx]),\n",
    "        'model_name': 'target',\n",
    "        'sample_index': idx,\n",
    "        'data_split': 'test'\n",
    "    })\n",
    "\n",
    "# Calculate samples to take from each shadow model\n",
    "shadow_samples_per_model = int(0.2 * data_size)  # 20% of data_size\n",
    "\n",
    "# Add shadow model predictions with metadata\n",
    "for i in np.arange(ns):\n",
    "    model_shadow = load_model(f'UCI_Adult_shadow_{data_size}_{i}.h5')\n",
    "    \n",
    "    # Get predictions from shadow model\n",
    "    shadow_tr_preds = model_shadow.predict(xtr_shadow)\n",
    "    shadow_ts_preds = model_shadow.predict(xts_shadow)\n",
    "    \n",
    "    # Randomly select indices from both train and test sets\n",
    "    train_indices = np.random.choice(len(shadow_tr_preds), \n",
    "                                   shadow_samples_per_model // 2, \n",
    "                                   replace=False)\n",
    "    test_indices = np.random.choice(len(shadow_ts_preds), \n",
    "                                  shadow_samples_per_model // 2, \n",
    "                                  replace=False)\n",
    "    \n",
    "    # Add selected training samples\n",
    "    for idx in train_indices:\n",
    "        test_set_data.append({\n",
    "            'prediction': float(shadow_tr_preds[idx]),\n",
    "            'is_member': 0,  # member of training set\n",
    "            'true_label': int(ytr_shadow[idx]),\n",
    "            'model_name': f'shadow_{i}',\n",
    "            'sample_index': idx,\n",
    "            'data_split': 'train'\n",
    "        })\n",
    "    \n",
    "    # Add selected test samples\n",
    "    for idx in test_indices:\n",
    "        test_set_data.append({\n",
    "            'prediction': float(shadow_ts_preds[idx]),\n",
    "            'is_member': 1,  # non-member (test set)\n",
    "            'true_label': int(yts_shadow[idx]),\n",
    "            'model_name': f'shadow_{i}',\n",
    "            'sample_index': idx,\n",
    "            'data_split': 'test'\n",
    "        })\n",
    "\n",
    "# Convert to pandas DataFrame for easier handling\n",
    "test_set_df = pd.DataFrame(test_set_data)\n",
    "\n",
    "# Create arrays for attack model\n",
    "xts_att_combined = test_set_df['prediction'].values.reshape(-1, 1)\n",
    "yts_att_combined = test_set_df['is_member'].values.reshape(-1, 1)\n",
    "xts_att_truelabels_combined = test_set_df['true_label'].values\n",
    "\n",
    "# Save both the structured DataFrame and the arrays\n",
    "test_set_dict = {\n",
    "    'xts_att': xts_att_combined,\n",
    "    'yts_att': yts_att_combined,\n",
    "    'xts_att_truelabels': xts_att_truelabels_combined,\n",
    "    'metadata': test_set_df\n",
    "}\n",
    "fname = f'./att_test_data_tracked_{data_size}'\n",
    "np.save(fname, test_set_dict)\n",
    "\n",
    "# Train attack model with new test set\n",
    "hist_attack = model_attack.fit(xtr_att, ytr_att,\n",
    "                             batch_size=32,\n",
    "                             epochs=100,\n",
    "                             validation_data=(xts_att_combined, yts_att_combined),\n",
    "                             shuffle=True, verbose=0)\n",
    "\n",
    "# Example analysis using the metadata\n",
    "print(\"\\nTest Set Summary:\")\n",
    "print(\"\\nSamples per model:\")\n",
    "print(test_set_df.groupby('model_name').size())\n",
    "\n",
    "print(\"\\nMember/Non-member distribution:\")\n",
    "print(test_set_df.groupby(['model_name', 'is_member']).size().unstack())\n",
    "\n",
    "# Function to analyze attack model performance by source\n",
    "def analyze_performance_by_source(attack_model, test_set_df):\n",
    "    predictions = attack_model.predict(test_set_df['prediction'].values.reshape(-1, 1))\n",
    "    test_set_df['attack_prediction'] = predictions\n",
    "    \n",
    "    print(\"\\nPerformance Analysis by Source:\")\n",
    "    for model_name in test_set_df['model_name'].unique():\n",
    "        model_data = test_set_df[test_set_df['model_name'] == model_name]\n",
    "        acc = ((model_data['attack_prediction'].round() == model_data['is_member']).mean())\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(f\"Accuracy: {acc:.3f}\")\n",
    "        \n",
    "        # Confusion matrix per model\n",
    "        members_correct = ((model_data['attack_prediction'].round() == model_data['is_member']) & \n",
    "                         (model_data['is_member'] == 0)).sum()\n",
    "        nonmembers_correct = ((model_data['attack_prediction'].round() == model_data['is_member']) & \n",
    "                            (model_data['is_member'] == 1)).sum()\n",
    "        print(f\"Correctly identified members: {members_correct}\")\n",
    "        print(f\"Correctly identified non-members: {nonmembers_correct}\")\n",
    "\n",
    "# Run performance analysis\n",
    "analyze_performance_by_source(model_attack, test_set_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7fb303f-562c-4ca8-a0ff-08a63d59d3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xts_att_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b9e166-92f5-43e4-92f2-10e2516e2d08",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1523d839-55f0-4879-8ab9-47208266c901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/emanuel/sdd_sata/projetos/projeto_mestrado_ofc/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/media/emanuel/sdd_sata/projetos/projeto_mestrado_ofc/.venv/lib/python3.12/site-packages/shap/explainers/_deep/deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n",
      "/media/emanuel/sdd_sata/projetos/projeto_mestrado_ofc/.venv/lib/python3.12/site-packages/shap/explainers/_deep/deep_tf.py:155: UserWarning: You have provided over 5k background samples! For better performance consider using smaller random sample.\n",
      "  warnings.warn(\"You have provided over 5k background samples! For better performance consider using smaller random sample.\")\n",
      "/media/emanuel/sdd_sata/projetos/projeto_mestrado_ofc/.venv/lib/python3.12/site-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: keras_tensor_24\n",
      "Received: inputs=['Tensor(shape=(100000, 1))']\n",
      "  warnings.warn(msg)\n",
      "/media/emanuel/sdd_sata/projetos/projeto_mestrado_ofc/.venv/lib/python3.12/site-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: keras_tensor_24\n",
      "Received: inputs=['Tensor(shape=(200000, 1))']\n",
      "  warnings.warn(msg)\n",
      "/media/emanuel/sdd_sata/projetos/projeto_mestrado_ofc/.venv/lib/python3.12/site-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: keras_tensor_24\n",
      "Received: inputs=['Tensor(shape=(30000, 1))']\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "# Assuming you have a trained attack model (`model_attack`) and the `test_set_df` DataFrame\n",
    "\n",
    "# Calculate SHAP values\n",
    "explainer = shap.DeepExplainer(model_attack, xtr_att) \n",
    "shap_values = explainer.shap_values(xts_att_combined) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "733801ba-0e82-4765-9f87-b9d9bfbff7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>is_member</th>\n",
       "      <th>true_label</th>\n",
       "      <th>model_name</th>\n",
       "      <th>sample_index</th>\n",
       "      <th>data_split</th>\n",
       "      <th>attack_prediction</th>\n",
       "      <th>shap_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.526538</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>target</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.500346</td>\n",
       "      <td>0.000444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.597783</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>target</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.500592</td>\n",
       "      <td>0.000691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.535234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>target</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>0.500376</td>\n",
       "      <td>0.000474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>target</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>0.499532</td>\n",
       "      <td>-0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.599347</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>target</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>0.500597</td>\n",
       "      <td>0.000696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>0.358120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_4</td>\n",
       "      <td>7543</td>\n",
       "      <td>test</td>\n",
       "      <td>0.499788</td>\n",
       "      <td>-0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0.029613</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_4</td>\n",
       "      <td>2179</td>\n",
       "      <td>test</td>\n",
       "      <td>0.499588</td>\n",
       "      <td>-0.000313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0.063828</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_4</td>\n",
       "      <td>1110</td>\n",
       "      <td>test</td>\n",
       "      <td>0.499465</td>\n",
       "      <td>-0.000436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>0.000946</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_4</td>\n",
       "      <td>3481</td>\n",
       "      <td>test</td>\n",
       "      <td>0.499744</td>\n",
       "      <td>-0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>0.508347</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_4</td>\n",
       "      <td>7195</td>\n",
       "      <td>test</td>\n",
       "      <td>0.500283</td>\n",
       "      <td>0.000382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       prediction  is_member  true_label model_name  sample_index data_split  \\\n",
       "0        0.526538          0           1     target             0      train   \n",
       "1        0.597783          0           0     target             1      train   \n",
       "2        0.535234          0           0     target             2      train   \n",
       "3        0.043160          0           0     target             3      train   \n",
       "4        0.599347          0           1     target             4      train   \n",
       "...           ...        ...         ...        ...           ...        ...   \n",
       "29995    0.358120          1           0   shadow_4          7543       test   \n",
       "29996    0.029613          1           0   shadow_4          2179       test   \n",
       "29997    0.063828          1           0   shadow_4          1110       test   \n",
       "29998    0.000946          1           0   shadow_4          3481       test   \n",
       "29999    0.508347          1           0   shadow_4          7195       test   \n",
       "\n",
       "       attack_prediction  shap_value  \n",
       "0               0.500346    0.000444  \n",
       "1               0.500592    0.000691  \n",
       "2               0.500376    0.000474  \n",
       "3               0.499532   -0.000369  \n",
       "4               0.500597    0.000696  \n",
       "...                  ...         ...  \n",
       "29995           0.499788   -0.000113  \n",
       "29996           0.499588   -0.000313  \n",
       "29997           0.499465   -0.000436  \n",
       "29998           0.499744   -0.000157  \n",
       "29999           0.500283    0.000382  \n",
       "\n",
       "[30000 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_df['shap_value'] = shap_values[:, 0] \n",
    "test_set_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "155ce86e-5a7a-4c22-9e8f-9b17285caead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>is_member</th>\n",
       "      <th>true_label</th>\n",
       "      <th>model_name</th>\n",
       "      <th>sample_index</th>\n",
       "      <th>data_split</th>\n",
       "      <th>attack_prediction</th>\n",
       "      <th>shap_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.526538</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>target</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.500346</td>\n",
       "      <td>0.000444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.597783</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>target</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.500592</td>\n",
       "      <td>0.000691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.535234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>target</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>0.500376</td>\n",
       "      <td>0.000474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>target</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>0.499532</td>\n",
       "      <td>-0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.599347</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>target</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>0.500597</td>\n",
       "      <td>0.000696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0.001068</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>target</td>\n",
       "      <td>9995</td>\n",
       "      <td>test</td>\n",
       "      <td>0.499743</td>\n",
       "      <td>-0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0.002034</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>target</td>\n",
       "      <td>9996</td>\n",
       "      <td>test</td>\n",
       "      <td>0.499737</td>\n",
       "      <td>-0.000164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0.018991</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>target</td>\n",
       "      <td>9997</td>\n",
       "      <td>test</td>\n",
       "      <td>0.499640</td>\n",
       "      <td>-0.000261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0.051447</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>target</td>\n",
       "      <td>9998</td>\n",
       "      <td>test</td>\n",
       "      <td>0.499502</td>\n",
       "      <td>-0.000399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0.552394</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>target</td>\n",
       "      <td>9999</td>\n",
       "      <td>test</td>\n",
       "      <td>0.500435</td>\n",
       "      <td>0.000534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       prediction  is_member  true_label model_name  sample_index data_split  \\\n",
       "0        0.526538          0           1     target             0      train   \n",
       "1        0.597783          0           0     target             1      train   \n",
       "2        0.535234          0           0     target             2      train   \n",
       "3        0.043160          0           0     target             3      train   \n",
       "4        0.599347          0           1     target             4      train   \n",
       "...           ...        ...         ...        ...           ...        ...   \n",
       "19995    0.001068          1           0     target          9995       test   \n",
       "19996    0.002034          1           0     target          9996       test   \n",
       "19997    0.018991          1           0     target          9997       test   \n",
       "19998    0.051447          1           0     target          9998       test   \n",
       "19999    0.552394          1           1     target          9999       test   \n",
       "\n",
       "       attack_prediction  shap_value  \n",
       "0               0.500346    0.000444  \n",
       "1               0.500592    0.000691  \n",
       "2               0.500376    0.000474  \n",
       "3               0.499532   -0.000369  \n",
       "4               0.500597    0.000696  \n",
       "...                  ...         ...  \n",
       "19995           0.499743   -0.000158  \n",
       "19996           0.499737   -0.000164  \n",
       "19997           0.499640   -0.000261  \n",
       "19998           0.499502   -0.000399  \n",
       "19999           0.500435    0.000534  \n",
       "\n",
       "[20000 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter for target model predictions\n",
    "target_model_data = test_set_df[test_set_df['model_name'] == 'target']\n",
    "target_model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fb149dd-70b0-4de7-a5c7-30d03a74de0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>is_member</th>\n",
       "      <th>true_label</th>\n",
       "      <th>model_name</th>\n",
       "      <th>sample_index</th>\n",
       "      <th>data_split</th>\n",
       "      <th>attack_prediction</th>\n",
       "      <th>shap_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>0.043499</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>shadow_0</td>\n",
       "      <td>661</td>\n",
       "      <td>train</td>\n",
       "      <td>0.499531</td>\n",
       "      <td>-0.000370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20001</th>\n",
       "      <td>0.000714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_0</td>\n",
       "      <td>7922</td>\n",
       "      <td>train</td>\n",
       "      <td>0.499745</td>\n",
       "      <td>-0.000156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20002</th>\n",
       "      <td>0.010339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_0</td>\n",
       "      <td>5974</td>\n",
       "      <td>train</td>\n",
       "      <td>0.499687</td>\n",
       "      <td>-0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20003</th>\n",
       "      <td>0.023567</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_0</td>\n",
       "      <td>5661</td>\n",
       "      <td>train</td>\n",
       "      <td>0.499617</td>\n",
       "      <td>-0.000284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20004</th>\n",
       "      <td>0.173442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_0</td>\n",
       "      <td>9250</td>\n",
       "      <td>train</td>\n",
       "      <td>0.499384</td>\n",
       "      <td>-0.000517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21995</th>\n",
       "      <td>0.022513</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_0</td>\n",
       "      <td>4681</td>\n",
       "      <td>test</td>\n",
       "      <td>0.499622</td>\n",
       "      <td>-0.000279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21996</th>\n",
       "      <td>0.015966</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_0</td>\n",
       "      <td>1838</td>\n",
       "      <td>test</td>\n",
       "      <td>0.499656</td>\n",
       "      <td>-0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21997</th>\n",
       "      <td>0.597008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>shadow_0</td>\n",
       "      <td>5406</td>\n",
       "      <td>test</td>\n",
       "      <td>0.500589</td>\n",
       "      <td>0.000688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21998</th>\n",
       "      <td>0.006328</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_0</td>\n",
       "      <td>7373</td>\n",
       "      <td>test</td>\n",
       "      <td>0.499711</td>\n",
       "      <td>-0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21999</th>\n",
       "      <td>0.161404</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>shadow_0</td>\n",
       "      <td>6333</td>\n",
       "      <td>test</td>\n",
       "      <td>0.499376</td>\n",
       "      <td>-0.000525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       prediction  is_member  true_label model_name  sample_index data_split  \\\n",
       "20000    0.043499          0           1   shadow_0           661      train   \n",
       "20001    0.000714          0           0   shadow_0          7922      train   \n",
       "20002    0.010339          0           0   shadow_0          5974      train   \n",
       "20003    0.023567          0           0   shadow_0          5661      train   \n",
       "20004    0.173442          0           0   shadow_0          9250      train   \n",
       "...           ...        ...         ...        ...           ...        ...   \n",
       "21995    0.022513          1           0   shadow_0          4681       test   \n",
       "21996    0.015966          1           0   shadow_0          1838       test   \n",
       "21997    0.597008          1           1   shadow_0          5406       test   \n",
       "21998    0.006328          1           0   shadow_0          7373       test   \n",
       "21999    0.161404          1           1   shadow_0          6333       test   \n",
       "\n",
       "       attack_prediction  shap_value  \n",
       "20000           0.499531   -0.000370  \n",
       "20001           0.499745   -0.000156  \n",
       "20002           0.499687   -0.000214  \n",
       "20003           0.499617   -0.000284  \n",
       "20004           0.499384   -0.000517  \n",
       "...                  ...         ...  \n",
       "21995           0.499622   -0.000279  \n",
       "21996           0.499656   -0.000245  \n",
       "21997           0.500589    0.000688  \n",
       "21998           0.499711   -0.000191  \n",
       "21999           0.499376   -0.000525  \n",
       "\n",
       "[2000 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter for a specific shadow model (e.g., shadow_0)\n",
    "shadow_model_data = test_set_df[test_set_df['model_name'] == 'shadow_0']\n",
    "shadow_model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0276e57b-3247-4de2-b8ae-6e634227f68d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
