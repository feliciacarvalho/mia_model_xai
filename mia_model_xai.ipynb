{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "G5qwQ2q54Kdy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 11:58:20.622096: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-20 11:58:20.622568: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-20 11:58:20.624699: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-20 11:58:20.630439: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737385100.640064   83135 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737385100.642787   83135 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-20 11:58:20.653382: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.models import load_model #save and load models\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import average_precision_score\n",
    "import tensorflow.keras.backend as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "S_wJvrUv4t2W"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/adult.data',  names=[\n",
    "        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n",
    "        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n",
    "        \"Hours per week\", \"Country\", \"Target\"],\n",
    "        sep=r'\\s*,\\s*',\n",
    "        engine='python',\n",
    "        na_values=\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "l8g_apGA5xBo"
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"data/adult.test\",\n",
    "    names=[\n",
    "        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n",
    "        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n",
    "        \"Hours per week\", \"Country\", \"Target\"],\n",
    "        sep=r'\\s*,\\s*',\n",
    "        engine='python',\\\n",
    "        na_values=\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fLvIAEEP5zNz"
   },
   "outputs": [],
   "source": [
    "data = pd.concat([df, df1], ignore_index= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZHpMx0zX6GPc",
    "outputId": "4decd040-6e67-4c65-9b29-075b0a1c4d5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Workclass', 'fnlwgt', 'Education', 'Education-Num', 'Martial Status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Capital Gain', 'Capital Loss', 'Hours per week', 'Country', 'Target']\n",
      "(48842, 15)\n"
     ]
    }
   ],
   "source": [
    "names_cloud = data.columns.tolist()\n",
    "print(names_cloud)\n",
    "X = np.array(data[names_cloud])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3SJl9iri6itB",
    "outputId": "8911bf6e-0317-4585-ea11-eba06f9f1eb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    37155\n",
      "1    11687\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_83135/3481380141.py:2: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  print(pd.value_counts(pd.Series(y)))\n"
     ]
    }
   ],
   "source": [
    "y = (data['Target'].map({\"<=50K\":0,\">50K\":1})).values\n",
    "print(pd.value_counts(pd.Series(y)))\n",
    "data.drop('Target',axis=1, inplace =True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6iQcyq27xM0",
    "outputId": "e25e6f71-b52c-4f5a-9b06-535cbfea71ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Workclass', 'Education', 'Martial Status', 'Occupation',\n",
      "       'Relationship', 'Race', 'Sex', 'Country'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "categorical_features = data.select_dtypes(include=['object']).columns\n",
    "print(categorical_features)\n",
    "ohc_category = ['Workclass', 'Education', 'Martial Status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Country']\n",
    "df_ohc = pd.get_dummies(data, columns = ohc_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F-LC7vMbzxId",
    "outputId": "0c9727d7-7921-433c-8a57-2944487a2afd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Variable: Target\n",
      "Predictors: ['Age', 'fnlwgt', 'Education-Num', 'Capital Gain', 'Capital Loss', 'Hours per week', 'Workclass_Federal-gov', 'Workclass_Local-gov', 'Workclass_Never-worked', 'Workclass_Private', 'Workclass_Self-emp-inc', 'Workclass_Self-emp-not-inc', 'Workclass_State-gov', 'Workclass_Without-pay', 'Education_10th', 'Education_11th', 'Education_12th', 'Education_1st-4th', 'Education_5th-6th', 'Education_7th-8th', 'Education_9th', 'Education_Assoc-acdm', 'Education_Assoc-voc', 'Education_Bachelors', 'Education_Doctorate', 'Education_HS-grad', 'Education_Masters', 'Education_Preschool', 'Education_Prof-school', 'Education_Some-college', 'Martial Status_Divorced', 'Martial Status_Married-AF-spouse', 'Martial Status_Married-civ-spouse', 'Martial Status_Married-spouse-absent', 'Martial Status_Never-married', 'Martial Status_Separated', 'Martial Status_Widowed', 'Occupation_Adm-clerical', 'Occupation_Armed-Forces', 'Occupation_Craft-repair', 'Occupation_Exec-managerial', 'Occupation_Farming-fishing', 'Occupation_Handlers-cleaners', 'Occupation_Machine-op-inspct', 'Occupation_Other-service', 'Occupation_Priv-house-serv', 'Occupation_Prof-specialty', 'Occupation_Protective-serv', 'Occupation_Sales', 'Occupation_Tech-support', 'Occupation_Transport-moving', 'Relationship_Husband', 'Relationship_Not-in-family', 'Relationship_Other-relative', 'Relationship_Own-child', 'Relationship_Unmarried', 'Relationship_Wife', 'Race_Amer-Indian-Eskimo', 'Race_Asian-Pac-Islander', 'Race_Black', 'Race_Other', 'Race_White', 'Sex_Female', 'Sex_Male', 'Country_Cambodia', 'Country_Canada', 'Country_China', 'Country_Columbia', 'Country_Cuba', 'Country_Dominican-Republic', 'Country_Ecuador', 'Country_El-Salvador', 'Country_England', 'Country_France', 'Country_Germany', 'Country_Greece', 'Country_Guatemala', 'Country_Haiti', 'Country_Holand-Netherlands', 'Country_Honduras', 'Country_Hong', 'Country_Hungary', 'Country_India', 'Country_Iran', 'Country_Ireland', 'Country_Italy', 'Country_Jamaica', 'Country_Japan', 'Country_Laos', 'Country_Mexico', 'Country_Nicaragua', 'Country_Outlying-US(Guam-USVI-etc)', 'Country_Peru', 'Country_Philippines', 'Country_Poland', 'Country_Portugal', 'Country_Puerto-Rico', 'Country_Scotland', 'Country_South', 'Country_Taiwan', 'Country_Thailand', 'Country_Trinadad&Tobago', 'Country_United-States', 'Country_Vietnam', 'Country_Yugoslavia']\n",
      "Number of data samples : 48842\n",
      "Number of Predictor Features : 105\n"
     ]
    }
   ],
   "source": [
    "names_x = df_ohc.columns.tolist()\n",
    "print(\"Target Variable: Target\")\n",
    "print(\"Predictors: \"+str(names_x))\n",
    "x = np.array(df_ohc[names_x])\n",
    "print(\"Number of data samples : {0:d}\".format(x.shape[0]))\n",
    "print(\"Number of Predictor Features : {0:d}\".format(x.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ambYSyJPxV3t"
   },
   "source": [
    "# Modelo Alvo Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dJLwG5cQ8LIB",
    "outputId": "3314a13f-0332-4941-95a0-1f02992626bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23509 38928 23796 ...   919 38467 10742]\n"
     ]
    }
   ],
   "source": [
    "x = x.astype('float32')\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "\n",
    "data_size = 10000\n",
    "ns = 5 #number of shadow models for one data_size\n",
    "\n",
    "nout = 1\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "sh = np.arange(x.shape[0])\n",
    "np.random.shuffle(sh)\n",
    "target_rep = np.zeros((1,x.shape[0]))\n",
    "target_rep[0,:] = sh\n",
    "print(sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "Usg48OfJxaq8",
    "outputId": "030c668f-3a39-44d3-c1b2-43683b4702db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/emanuel/sdd_sata/projetos/projeto_mestrado_ofc/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "W0000 00:00:1737385134.724372   83135 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/media/emanuel/sdd_sata/projetos/projeto_mestrado_ofc/.venv/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">530</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m530\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">536</span> (2.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m536\u001b[0m (2.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">536</span> (2.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m536\u001b[0m (2.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "For target model with training datasize = 10000\n",
      "Training accuracy = 0.850000\n",
      "Validation accuracy = 0.849800\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step\n"
     ]
    }
   ],
   "source": [
    "k.clear_session()\n",
    "\n",
    "xtr_target = x[sh[:data_size]]\n",
    "ytr_target = y[sh[:data_size]]\n",
    "xts_target = x[sh[data_size:data_size*2]]\n",
    "yts_target = y[sh[data_size:2*data_size]]\n",
    "\n",
    "shadow_rep = np.zeros((5,x.shape[0]-2*data_size))\n",
    "sh1 = sh[2*data_size:]\n",
    "xtr_att = np.zeros((2*data_size*ns,1))\n",
    "ytr_att = np.zeros((2*data_size*ns,1))\n",
    "xtr_att_truelabels = np.zeros((2*data_size*ns,))\n",
    "\n",
    "model_target = Sequential()\n",
    "model_target.add(Dense(5, input_shape =(x.shape[1],), activation='sigmoid', name = 'hidden'))\n",
    "model_target.add(Dense(1, activation='sigmoid', name = 'output'))\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001, decay = 1e-7)\n",
    "model_target.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "print(model_target.summary())\n",
    "hist_target = model_target.fit(xtr_target, ytr_target,\n",
    "                  batch_size = 32,\n",
    "                  epochs = 100,\n",
    "                  validation_data=(xts_target, yts_target), shuffle=True, verbose=0)\n",
    "print('\\n\\nFor target model with training datasize = %d'%data_size)\n",
    "print('Training accuracy = %f'%hist_target.history['accuracy'][-1])\n",
    "print('Validation accuracy = %f'%hist_target.history['val_accuracy'][-1])\n",
    "model_target_name = 'UCI_Adult_target_'+str(data_size)+'.h5'\n",
    "\n",
    "model_target.save(model_target_name)\n",
    "\n",
    "ytemp_tr_target = model_target.predict(xtr_target)\n",
    "ytemp_ts_target = model_target.predict(xts_target)\n",
    "\n",
    "xts_att = np.vstack((ytemp_tr_target,ytemp_ts_target))\n",
    "yts_att = np.zeros((2*data_size,1))\n",
    "yts_att[data_size:2*data_size] = 1\n",
    "xts_att_truelabels = np.vstack((ytr_target,yts_target))\n",
    "xts_att_dict = {'xts_att':xts_att,'yts_att':yts_att,'xts_att_truelabels':xts_att_truelabels}\n",
    "fname = './att_test_data_'+str(data_size)\n",
    "np.save(fname,xts_att_dict)\n",
    "datafile = './data_adult_target_'+str(data_size)\n",
    "np.save(datafile,target_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Sombra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PKaOpPay1_7X",
    "outputId": "593ea3a8-729a-4378-b363-aff4f10f17a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shadow Model Summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">530</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m530\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">536</span> (2.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m536\u001b[0m (2.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">536</span> (2.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m536\u001b[0m (2.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Shadow model no: 0\n",
      "\n",
      "\n",
      "For shadow model with training datasize = 10000\n",
      "Training accuracy = 0.855900\n",
      "Validation accuracy = 0.851200\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCI_Adult_shadow_10000_0.h5\n",
      "Shadow model no: 1\n",
      "\n",
      "\n",
      "For shadow model with training datasize = 10000\n",
      "Training accuracy = 0.859100\n",
      "Validation accuracy = 0.850500\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCI_Adult_shadow_10000_1.h5\n",
      "Shadow model no: 2\n",
      "\n",
      "\n",
      "For shadow model with training datasize = 10000\n",
      "Training accuracy = 0.858800\n",
      "Validation accuracy = 0.848700\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCI_Adult_shadow_10000_2.h5\n",
      "Shadow model no: 3\n",
      "\n",
      "\n",
      "For shadow model with training datasize = 10000\n",
      "Training accuracy = 0.863600\n",
      "Validation accuracy = 0.845600\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCI_Adult_shadow_10000_3.h5\n",
      "Shadow model no: 4\n",
      "\n",
      "\n",
      "For shadow model with training datasize = 10000\n",
      "Training accuracy = 0.857800\n",
      "Validation accuracy = 0.850100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCI_Adult_shadow_10000_4.h5\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(ns):\n",
    "\n",
    "    np.random.shuffle(sh1)\n",
    "    shadow_rep[i,:] = sh1\n",
    "    xtr_shadow = x[sh1[:data_size]]\n",
    "    ytr_shadow = y[sh1[:data_size]]\n",
    "    xts_shadow = x[sh1[data_size:2*data_size]]\n",
    "    yts_shadow = y[sh1[data_size:2*data_size]]\n",
    "\n",
    "    model_shadow = Sequential()\n",
    "    model_shadow.add(Dense(5, input_shape =(x.shape[1],), activation='sigmoid', name = 'hidden'))\n",
    "    model_shadow.add(Dense(1, activation='sigmoid', name = 'output'))\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001, decay=1e-7)\n",
    "    model_shadow.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    if i == 0:\n",
    "        print(\"Shadow Model Summary\")\n",
    "        print(model_shadow.summary())\n",
    "    hist_shadow = model_shadow.fit(xtr_shadow, ytr_shadow,\n",
    "                  batch_size = 32,\n",
    "                  epochs = 100,\n",
    "                  validation_data=(xts_shadow, yts_shadow), shuffle=True, verbose=0)\n",
    "    print(\"Shadow model no: %d\"%i)\n",
    "    print('\\n\\nFor shadow model with training datasize = %d'%data_size)\n",
    "    print('Training accuracy = %f'%hist_shadow.history['accuracy'][-1])\n",
    "    print('Validation accuracy = %f'%hist_shadow.history['val_accuracy'][-1])\n",
    "\n",
    "    ytemp11 = model_shadow.predict(xtr_shadow)\n",
    "    ytemp22 = model_shadow.predict(xts_shadow)\n",
    "\n",
    "    model_shadow_name = 'UCI_Adult_shadow_'+str(data_size)+'_'+str(i)+'.h5'\n",
    "    print(model_shadow_name)\n",
    "    model_shadow.save(model_shadow_name)\n",
    "\n",
    "    xtr_att[i*2*data_size:(i+1)*2*data_size] = np.vstack((ytemp11,ytemp22))\n",
    "    ytr_att[((i*2)+1)*data_size:(i+1)*2*data_size] = 1\n",
    "    xtr_att_truelabels[i*2*data_size:(i+1)*2*data_size] = np.hstack((ytr_shadow,yts_shadow))\n",
    "\n",
    "datafile = './data_adult_shadow_'+str(data_size)\n",
    "np.save(datafile,shadow_rep)\n",
    "xtr_att_dict = {'xtr_att':xtr_att,'ytr_att':ytr_att,'xtr_att_truelabels':xtr_att_truelabels}\n",
    "fname = './att_train_data_'+str(data_size)\n",
    "np.save(fname,xtr_att_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Ataque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "id": "sYtHjgcd3tvs",
    "outputId": "b92e2c22-50e9-4f3d-ad89-a942272cea69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Model Summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m10\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> (64.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16\u001b[0m (64.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> (64.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16\u001b[0m (64.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "\n",
      "For attack model with training datasize = 100000\n",
      "Training accuracy = 0.499750\n",
      "Validation accuracy = 0.500000\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265us/step\n",
      "Average precision-recall score: 0.50\n"
     ]
    }
   ],
   "source": [
    "model_attack = Sequential()\n",
    "model_attack.add(Dense(5, input_shape = (xtr_att.shape[1],), activation='sigmoid', name = 'hidden'))\n",
    "model_attack.add(Dense(1, activation='sigmoid', name = 'output'))\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001, decay=1e-7)\n",
    "model_attack.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "print(\"Attack Model Summary\")\n",
    "print(model_attack.summary())\n",
    "hist_attack = model_attack.fit(xtr_att, ytr_att,\n",
    "                  batch_size = 32,\n",
    "                  epochs = 100,\n",
    "                  validation_data=(xts_att, yts_att), shuffle=True, verbose=0)\n",
    "print('\\n\\nFor attack model with training datasize = %d'%xtr_att.shape[0])\n",
    "print('Training accuracy = %f'%hist_attack.history['accuracy'][-1])\n",
    "print('Validation accuracy = %f'%hist_attack.history['val_accuracy'][-1])\n",
    "y_score = model_attack.predict(xts_att)\n",
    "average_precision = average_precision_score(yts_att, y_score)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AiuOSWtDjUi"
   },
   "source": [
    "## COmbinando amostras entre alvo e sombras no conjunto de teste do ataque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uj1-18zbDWw7",
    "outputId": "1f35b6ab-f3e5-4653-a94b-b1be4958b55d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step\n",
      "\n",
      "\n",
      "For attack model with training datasize = 100000\n",
      "Training accuracy = 0.498550\n",
      "Validation accuracy = 0.499733\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253us/step\n",
      "Average precision-recall score: 0.50\n"
     ]
    }
   ],
   "source": [
    "# # First, collect predictions from both target and shadow models for test set\n",
    "# # Assuming we want to use 20% of each shadow model's predictions in the test set\n",
    "\n",
    "# # Original target model predictions\n",
    "# ytemp_tr_target = model_target.predict(xtr_target)  # predictions on target train data\n",
    "# ytemp_ts_target = model_target.predict(xts_target)  # predictions on target test data\n",
    "\n",
    "# Calculate how many samples we want from each shadow model\n",
    "shadow_samples_per_model = int(0.2 * data_size)  # 20% of data_size\n",
    "total_shadow_samples = shadow_samples_per_model * ns  # ns is number of shadow models\n",
    "\n",
    "# Initialize arrays for combined test set\n",
    "xts_att_combined = np.zeros((2*data_size + total_shadow_samples, 1))\n",
    "yts_att_combined = np.zeros((2*data_size + total_shadow_samples, 1))\n",
    "xts_att_truelabels_combined = np.zeros((2*data_size + total_shadow_samples,))\n",
    "\n",
    "# First, add all target model predictions\n",
    "xts_att_combined[:2*data_size] = np.vstack((ytemp_tr_target, ytemp_ts_target))\n",
    "yts_att_combined[:data_size] = 0  # members (target train)\n",
    "yts_att_combined[data_size:2*data_size] = 1  # non-members (target test)\n",
    "xts_att_truelabels_combined[:2*data_size] = np.hstack((ytr_target, yts_target))\n",
    "\n",
    "# Then add portions of shadow model predictions\n",
    "current_index = 2*data_size\n",
    "\n",
    "for i in np.arange(ns):\n",
    "    # Load or get predictions from each shadow model\n",
    "    model_shadow = load_model(f'UCI_Adult_shadow_{data_size}_{i}.h5')\n",
    "\n",
    "    # Get predictions from shadow model\n",
    "    shadow_tr_preds = model_shadow.predict(xtr_shadow)  # predictions on shadow train data\n",
    "    shadow_ts_preds = model_shadow.predict(xts_shadow)  # predictions on shadow test data\n",
    "\n",
    "    # Randomly select samples from both train and test predictions\n",
    "    combined_preds = np.vstack((shadow_tr_preds, shadow_ts_preds))\n",
    "    combined_labels = np.hstack((np.zeros(data_size), np.ones(data_size)))  # 0 for members, 1 for non-members\n",
    "    combined_true_labels = np.hstack((ytr_shadow, yts_shadow))\n",
    "\n",
    "    # Randomly select indices\n",
    "    random_indices = np.random.choice(2*data_size, shadow_samples_per_model, replace=False)\n",
    "\n",
    "    # Add selected predictions and their labels to test set\n",
    "    end_index = current_index + shadow_samples_per_model\n",
    "    xts_att_combined[current_index:end_index] = combined_preds[random_indices].reshape(-1, 1)\n",
    "    yts_att_combined[current_index:end_index] = combined_labels[random_indices].reshape(-1, 1)\n",
    "    xts_att_truelabels_combined[current_index:end_index] = combined_true_labels[random_indices]\n",
    "\n",
    "    current_index = end_index\n",
    "\n",
    "# Save the combined test data\n",
    "xts_att_dict = {\n",
    "    'xts_att': xts_att_combined,\n",
    "    'yts_att': yts_att_combined,\n",
    "    'xts_att_truelabels': xts_att_truelabels_combined\n",
    "}\n",
    "fname = f'./att_test_data_combined_{data_size}'\n",
    "np.save(fname, xts_att_dict)\n",
    "\n",
    "# # Use this combined test set for attack model evaluation\n",
    "hist_attack = model_attack.fit(xtr_att, ytr_att,\n",
    "                             batch_size=32,\n",
    "                             epochs=100,\n",
    "                             validation_data=(xts_att_combined, yts_att_combined),\n",
    "                             shuffle=True, verbose=0)\n",
    "\n",
    "# Evaluate performance\n",
    "print('\\n\\nFor attack model with training datasize = %d' % xtr_att.shape[0])\n",
    "print('Training accuracy = %f' % hist_attack.history['accuracy'][-1])\n",
    "print('Validation accuracy = %f' % hist_attack.history['val_accuracy'][-1])\n",
    "y_score = model_attack.predict(xts_att_combined)\n",
    "average_precision = average_precision_score(yts_att_combined, y_score)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xIsEJl60Edzc",
    "outputId": "7fb5b11d-c4ea-4c81-be6f-ac9292772417"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xts_att: 30000\n",
      "yts_att: 30000\n",
      "xts_att_truelabels: 30000\n"
     ]
    }
   ],
   "source": [
    "for key, value in xts_att_dict.items():\n",
    "  print(f'{key}: {len(value)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_83135/1860021247.py:7: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  'prediction': float(ytemp_tr_target[idx]),\n",
      "/tmp/ipykernel_83135/1860021247.py:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  'prediction': float(ytemp_ts_target[idx]),\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_83135/1860021247.py:47: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  'prediction': float(shadow_tr_preds[idx]),\n",
      "/tmp/ipykernel_83135/1860021247.py:58: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  'prediction': float(shadow_ts_preds[idx]),\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step\n",
      "\n",
      "Test Set Summary:\n",
      "\n",
      "Samples per model:\n",
      "model_name\n",
      "shadow_0     2000\n",
      "shadow_1     2000\n",
      "shadow_2     2000\n",
      "shadow_3     2000\n",
      "shadow_4     2000\n",
      "target      20000\n",
      "dtype: int64\n",
      "\n",
      "Member/Non-member distribution:\n",
      "is_member       0      1\n",
      "model_name              \n",
      "shadow_0     1000   1000\n",
      "shadow_1     1000   1000\n",
      "shadow_2     1000   1000\n",
      "shadow_3     1000   1000\n",
      "shadow_4     1000   1000\n",
      "target      10000  10000\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244us/step\n",
      "\n",
      "Performance Analysis by Source:\n",
      "\n",
      "target:\n",
      "Accuracy: 0.499\n",
      "Correctly identified members: 9033\n",
      "Correctly identified non-members: 941\n",
      "\n",
      "shadow_0:\n",
      "Accuracy: 0.500\n",
      "Correctly identified members: 903\n",
      "Correctly identified non-members: 98\n",
      "\n",
      "shadow_1:\n",
      "Accuracy: 0.505\n",
      "Correctly identified members: 912\n",
      "Correctly identified non-members: 99\n",
      "\n",
      "shadow_2:\n",
      "Accuracy: 0.495\n",
      "Correctly identified members: 898\n",
      "Correctly identified non-members: 92\n",
      "\n",
      "shadow_3:\n",
      "Accuracy: 0.499\n",
      "Correctly identified members: 895\n",
      "Correctly identified non-members: 104\n",
      "\n",
      "shadow_4:\n",
      "Accuracy: 0.494\n",
      "Correctly identified members: 896\n",
      "Correctly identified non-members: 92\n"
     ]
    }
   ],
   "source": [
    "# Create a structured array to store predictions and metadata\n",
    "test_set_data = []\n",
    "\n",
    "# Add target model predictions with metadata\n",
    "for idx in range(len(ytemp_tr_target)):\n",
    "    test_set_data.append({\n",
    "        'prediction': float(ytemp_tr_target[idx]),\n",
    "        'is_member': 0,  # member of training set\n",
    "        'true_label': int(ytr_target[idx]),\n",
    "        'model_name': 'target',\n",
    "        'sample_index': idx,\n",
    "        'data_split': 'train'\n",
    "    })\n",
    "\n",
    "for idx in range(len(ytemp_ts_target)):\n",
    "    test_set_data.append({\n",
    "        'prediction': float(ytemp_ts_target[idx]),\n",
    "        'is_member': 1,  # non-member (test set)\n",
    "        'true_label': int(yts_target[idx]),\n",
    "        'model_name': 'target',\n",
    "        'sample_index': idx,\n",
    "        'data_split': 'test'\n",
    "    })\n",
    "\n",
    "# Calculate samples to take from each shadow model\n",
    "shadow_samples_per_model = int(0.2 * data_size)  # 20% of data_size\n",
    "\n",
    "# Add shadow model predictions with metadata\n",
    "for i in np.arange(ns):\n",
    "    model_shadow = load_model(f'UCI_Adult_shadow_{data_size}_{i}.h5')\n",
    "    \n",
    "    # Get predictions from shadow model\n",
    "    shadow_tr_preds = model_shadow.predict(xtr_shadow)\n",
    "    shadow_ts_preds = model_shadow.predict(xts_shadow)\n",
    "    \n",
    "    # Randomly select indices from both train and test sets\n",
    "    train_indices = np.random.choice(len(shadow_tr_preds), \n",
    "                                   shadow_samples_per_model // 2, \n",
    "                                   replace=False)\n",
    "    test_indices = np.random.choice(len(shadow_ts_preds), \n",
    "                                  shadow_samples_per_model // 2, \n",
    "                                  replace=False)\n",
    "    \n",
    "    # Add selected training samples\n",
    "    for idx in train_indices:\n",
    "        test_set_data.append({\n",
    "            'prediction': float(shadow_tr_preds[idx]),\n",
    "            'is_member': 0,  # member of training set\n",
    "            'true_label': int(ytr_shadow[idx]),\n",
    "            'model_name': f'shadow_{i}',\n",
    "            'sample_index': idx,\n",
    "            'data_split': 'train'\n",
    "        })\n",
    "    \n",
    "    # Add selected test samples\n",
    "    for idx in test_indices:\n",
    "        test_set_data.append({\n",
    "            'prediction': float(shadow_ts_preds[idx]),\n",
    "            'is_member': 1,  # non-member (test set)\n",
    "            'true_label': int(yts_shadow[idx]),\n",
    "            'model_name': f'shadow_{i}',\n",
    "            'sample_index': idx,\n",
    "            'data_split': 'test'\n",
    "        })\n",
    "\n",
    "# Convert to pandas DataFrame for easier handling\n",
    "test_set_df = pd.DataFrame(test_set_data)\n",
    "\n",
    "# Create arrays for attack model\n",
    "xts_att_combined = test_set_df['prediction'].values.reshape(-1, 1)\n",
    "yts_att_combined = test_set_df['is_member'].values.reshape(-1, 1)\n",
    "xts_att_truelabels_combined = test_set_df['true_label'].values\n",
    "\n",
    "# Save both the structured DataFrame and the arrays\n",
    "test_set_dict = {\n",
    "    'xts_att': xts_att_combined,\n",
    "    'yts_att': yts_att_combined,\n",
    "    'xts_att_truelabels': xts_att_truelabels_combined,\n",
    "    'metadata': test_set_df\n",
    "}\n",
    "fname = f'./att_test_data_tracked_{data_size}'\n",
    "np.save(fname, test_set_dict)\n",
    "\n",
    "# Train attack model with new test set\n",
    "hist_attack = model_attack.fit(xtr_att, ytr_att,\n",
    "                             batch_size=32,\n",
    "                             epochs=100,\n",
    "                             validation_data=(xts_att_combined, yts_att_combined),\n",
    "                             shuffle=True, verbose=0)\n",
    "\n",
    "# Example analysis using the metadata\n",
    "print(\"\\nTest Set Summary:\")\n",
    "print(\"\\nSamples per model:\")\n",
    "print(test_set_df.groupby('model_name').size())\n",
    "\n",
    "print(\"\\nMember/Non-member distribution:\")\n",
    "print(test_set_df.groupby(['model_name', 'is_member']).size().unstack())\n",
    "\n",
    "# Function to analyze attack model performance by source\n",
    "def analyze_performance_by_source(attack_model, test_set_df):\n",
    "    predictions = attack_model.predict(test_set_df['prediction'].values.reshape(-1, 1))\n",
    "    test_set_df['attack_prediction'] = predictions\n",
    "    \n",
    "    print(\"\\nPerformance Analysis by Source:\")\n",
    "    for model_name in test_set_df['model_name'].unique():\n",
    "        model_data = test_set_df[test_set_df['model_name'] == model_name]\n",
    "        acc = ((model_data['attack_prediction'].round() == model_data['is_member']).mean())\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(f\"Accuracy: {acc:.3f}\")\n",
    "        \n",
    "        # Confusion matrix per model\n",
    "        members_correct = ((model_data['attack_prediction'].round() == model_data['is_member']) & \n",
    "                         (model_data['is_member'] == 0)).sum()\n",
    "        nonmembers_correct = ((model_data['attack_prediction'].round() == model_data['is_member']) & \n",
    "                            (model_data['is_member'] == 1)).sum()\n",
    "        print(f\"Correctly identified members: {members_correct}\")\n",
    "        print(f\"Correctly identified non-members: {nonmembers_correct}\")\n",
    "\n",
    "# Run performance analysis\n",
    "analyze_performance_by_source(model_attack, test_set_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xts_att': array([[5.30722976e-01],\n",
       "        [6.42804265e-01],\n",
       "        [5.59235811e-01],\n",
       "        ...,\n",
       "        [5.61631732e-02],\n",
       "        [3.51279654e-04],\n",
       "        [5.24006605e-01]]),\n",
       " 'yts_att': array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]]),\n",
       " 'xts_att_truelabels': array([1, 0, 0, ..., 0, 0, 0]),\n",
       " 'metadata':        prediction  is_member  true_label model_name  sample_index data_split\n",
       " 0        0.530723          0           1     target             0      train\n",
       " 1        0.642804          0           0     target             1      train\n",
       " 2        0.559236          0           0     target             2      train\n",
       " 3        0.053497          0           0     target             3      train\n",
       " 4        0.638779          0           1     target             4      train\n",
       " ...           ...        ...         ...        ...           ...        ...\n",
       " 29995    0.372411          1           0   shadow_4          7543       test\n",
       " 29996    0.029370          1           0   shadow_4          2179       test\n",
       " 29997    0.056163          1           0   shadow_4          1110       test\n",
       " 29998    0.000351          1           0   shadow_4          3481       test\n",
       " 29999    0.524007          1           0   shadow_4          7195       test\n",
       " \n",
       " [30000 rows x 6 columns]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_dict{'metadata': }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xts_att: 30000\n",
      "yts_att: 30000\n",
      "xts_att_truelabels: 30000\n",
      "metadata: 30000\n"
     ]
    }
   ],
   "source": [
    "for key, value in test_set_dict.items():\n",
    "  print(f'{key}: {len(value)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>is_member</th>\n",
       "      <th>true_label</th>\n",
       "      <th>model_name</th>\n",
       "      <th>sample_index</th>\n",
       "      <th>data_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.530723</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>target</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.642804</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>target</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.559236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>target</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.053497</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>target</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.638779</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>target</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>0.372411</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_4</td>\n",
       "      <td>7543</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0.029370</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_4</td>\n",
       "      <td>2179</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0.056163</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_4</td>\n",
       "      <td>1110</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>0.000351</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_4</td>\n",
       "      <td>3481</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>0.524007</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_4</td>\n",
       "      <td>7195</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       prediction  is_member  true_label model_name  sample_index data_split\n",
       "0        0.530723          0           1     target             0      train\n",
       "1        0.642804          0           0     target             1      train\n",
       "2        0.559236          0           0     target             2      train\n",
       "3        0.053497          0           0     target             3      train\n",
       "4        0.638779          0           1     target             4      train\n",
       "...           ...        ...         ...        ...           ...        ...\n",
       "29995    0.372411          1           0   shadow_4          7543       test\n",
       "29996    0.029370          1           0   shadow_4          2179       test\n",
       "29997    0.056163          1           0   shadow_4          1110       test\n",
       "29998    0.000351          1           0   shadow_4          3481       test\n",
       "29999    0.524007          1           0   shadow_4          7195       test\n",
       "\n",
       "[30000 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2s68-vMDXXu"
   },
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "sNdxHr7v9viN",
    "outputId": "276bbfcd-a196-476f-ae99-484f76492383"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ExactExplainer explainer: 1001it [00:10,  6.77it/s]                          \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x190 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "# Criar o explicador SHAP para o modelo de ataque, com base nas previsões dos modelos sombra no conjunto de treinamento (xtr_att)\n",
    "explainer = shap.Explainer(model_attack, xtr_att[:1000])\n",
    "\n",
    "# Calcular os valores SHAP para as primeiras 1000 amostras do conjunto de teste (xts_att contém as previsões do modelo alvo)\n",
    "shap_values = explainer(xtr_att[:1000])  # xts_att contém as previsões do modelo alvo\n",
    "\n",
    "# Exibir um resumo das contribuições das características (as previsões dos modelos sombra)\n",
    "shap.summary_plot(shap_values, xtr_att[:1000])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "MSctXPvE90i6",
    "outputId": "4388face-8668-4a6c-d819-074cf2393874"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id='i05XQ9NEWVGL0X0YIR4YY'>\n",
       "<div style='color: #900; text-align: center;'>\n",
       "  <b>Visualization omitted, Javascript library not loaded!</b><br>\n",
       "  Have you run `initjs()` in this notebook? If this notebook was from another\n",
       "  user you must also trust this notebook (File -> Trust notebook). If you are viewing\n",
       "  this notebook on github the Javascript has been stripped for security. If you are using\n",
       "  JupyterLab this error is because a JupyterLab extension has not yet been written.\n",
       "</div></div>\n",
       " <script>\n",
       "   if (window.SHAP) SHAP.ReactDom.render(\n",
       "    SHAP.React.createElement(SHAP.AdditiveForceVisualizer, {\"outNames\": [\"f(x)\"], \"baseValue\": 0.5009300172328949, \"outValue\": 0.5009479522705078, \"link\": \"identity\", \"featureNames\": [\"Feature 0\"], \"features\": {\"0\": {\"effect\": 1.7935037612937244e-05, \"value\": 0.5740676522254944}}, \"plot_cmap\": \"RdBu\", \"labelMargin\": 20}),\n",
       "    document.getElementById('i05XQ9NEWVGL0X0YIR4YY')\n",
       "  );\n",
       "</script>"
      ],
      "text/plain": [
       "<shap.plots._force.AdditiveForceVisualizer at 0x7fc2411e4850>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizar as contribuições de uma amostra específica (primeira amostra, por exemplo)\n",
    "shap.force_plot(shap_values[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "oSFopGRXBVG9",
    "outputId": "fa8d7b16-3534-4430-bc5f-82b87d25c094"
   },
   "outputs": [],
   "source": [
    "# Visualizar a relação entre uma característica específica e sua contribuição (dependence plot)\n",
    "shap.dependence_plot(0, shap_values, xtr_att[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "88VbR14rDl-D",
    "outputId": "150fa331-c367-480b-dae3-b081fc42e93b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 amostras mais importantes para o treinamento do modelo de ataque:\n",
      "Amostra 50 com importância 0.00010251939296723744\n",
      "Amostra 387 com importância 0.00010359227657319448\n",
      "Amostra 7 com importância 0.0001040691137313976\n",
      "Amostra 304 com importância 0.00010585725307465932\n",
      "Amostra 920 com importância 0.00010716855525971791\n",
      "Amostra 216 com importância 0.00010818183422089955\n",
      "Amostra 312 com importância 0.00010818183422089955\n",
      "Amostra 574 com importância 0.00010818183422089955\n",
      "Amostra 762 com importância 0.00010818183422089955\n",
      "Amostra 931 com importância 0.00010818183422089955\n"
     ]
    }
   ],
   "source": [
    "importance = np.abs(shap_values.values).mean(axis=1)  # Média dos valores absolutos de SHAP para cada amostra\n",
    "\n",
    "# Ordenar as amostras por sua importância\n",
    "top_10_idx = np.argsort(importance)[-10:]  # Índices das 10 amostras mais importantes\n",
    "\n",
    "# Visualizar as 10 amostras mais importantes\n",
    "print(\"Top 10 amostras mais importantes para o treinamento do modelo de ataque:\")\n",
    "for idx in top_10_idx:\n",
    "    print(f\"Amostra {idx} com importância {importance[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDALWKcdDmQB"
   },
   "source": [
    "## SHAP Rastreado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# First create the structured test data with differences between models\n",
    "def create_model_differences_dataset(test_set_df):\n",
    "    # Pivot the predictions to get one column per model\n",
    "    model_predictions = pd.pivot_table(\n",
    "        test_set_df,\n",
    "        values='prediction',\n",
    "        index='sample_index',\n",
    "        columns='model_name',\n",
    "        aggfunc='first'\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Calculate differences between target and each shadow model\n",
    "    difference_features = []\n",
    "    feature_names = []\n",
    "    \n",
    "    # Get all shadow model names\n",
    "    shadow_models = [col for col in model_predictions.columns if 'shadow' in col]\n",
    "    \n",
    "    for shadow in shadow_models:\n",
    "        diff_col = f'diff_{shadow}_target'\n",
    "        model_predictions[diff_col] = model_predictions[shadow] - model_predictions['target']\n",
    "        difference_features.append(model_predictions[diff_col])\n",
    "        feature_names.append(f'Difference ({shadow} - target)')\n",
    "    \n",
    "    # Stack differences into a numpy array\n",
    "    X_diff = np.column_stack(difference_features)\n",
    "    \n",
    "    return X_diff, feature_names\n",
    "\n",
    "# Create the difference features\n",
    "X_diff, feature_names = create_model_differences_dataset(test_set_df)\n",
    "\n",
    "# Create SHAP explainer with the difference features\n",
    "explainer = shap.Explainer(model_attack, X_diff)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer(X_diff)\n",
    "\n",
    "# Plot SHAP summary\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values, X_diff, feature_names=feature_names)\n",
    "plt.title(\"SHAP Values for Model Differences\")\n",
    "\n",
    "# Create detailed analysis of SHAP values\n",
    "def analyze_shap_by_membership(shap_values, X_diff, test_set_df, feature_names):\n",
    "    # Get unique sample indices\n",
    "    sample_indices = test_set_df['sample_index'].unique()\n",
    "    \n",
    "    # Create DataFrame with SHAP values and metadata\n",
    "    shap_df = pd.DataFrame(shap_values.values, columns=feature_names)\n",
    "    shap_df['is_member'] = test_set_df['is_member']\n",
    "    shap_df['true_label'] = test_set_df['true_label']\n",
    "    \n",
    "    print(\"\\nSHAP Analysis by Membership Status:\")\n",
    "    print(\"\\nAverage absolute SHAP values for members vs non-members:\")\n",
    "    member_shap = shap_df[shap_df['is_member'] == 0][feature_names].abs().mean()\n",
    "    nonmember_shap = shap_df[shap_df['is_member'] == 1][feature_names].abs().mean()\n",
    "    \n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Member Impact': member_shap,\n",
    "        'Non-member Impact': nonmember_shap\n",
    "    })\n",
    "    print(comparison_df)\n",
    "    \n",
    "    # Plot SHAP values separately for members and non-members\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    shap.summary_plot(\n",
    "        shap_values[test_set_df['is_member'] == 0],\n",
    "        X_diff[test_set_df['is_member'] == 0],\n",
    "        feature_names=feature_names,\n",
    "        title=\"SHAP Values for Members\",\n",
    "        show=False\n",
    "    )\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    shap.summary_plot(\n",
    "        shap_values[test_set_df['is_member'] == 1],\n",
    "        X_diff[test_set_df['is_member'] == 1],\n",
    "        feature_names=feature_names,\n",
    "        title=\"SHAP Values for Non-members\",\n",
    "        show=False\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run the detailed SHAP analysis\n",
    "analyze_shap_by_membership(shap_values, X_diff, test_set_df, feature_names)\n",
    "\n",
    "# Save the SHAP analysis results\n",
    "shap_results = {\n",
    "    'shap_values': shap_values.values,\n",
    "    'feature_names': feature_names,\n",
    "    'X_diff': X_diff,\n",
    "    'metadata': test_set_df\n",
    "}\n",
    "np.save(f'./shap_analysis_results_{data_size}.npy', shap_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHap Rastreado 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/media/emanuel/sdd_sata/projetos/projeto_mestrado_ofc/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'target'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X_diff, feature_names\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Create training and test datasets with differences\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m X_train_diff, feature_names \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_difference_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m X_test_diff, _ \u001b[38;5;241m=\u001b[39m create_difference_features(test_set_df, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Create and train the modified attack model\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[28], line 38\u001b[0m, in \u001b[0;36mcreate_difference_features\u001b[0;34m(predictions_df, is_training)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shadow \u001b[38;5;129;01min\u001b[39;00m shadow_models:\n\u001b[1;32m     37\u001b[0m     diff_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiff_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshadow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_target\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 38\u001b[0m     model_predictions[diff_col] \u001b[38;5;241m=\u001b[39m model_predictions[shadow] \u001b[38;5;241m-\u001b[39m \u001b[43mmodel_predictions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     39\u001b[0m     difference_features\u001b[38;5;241m.\u001b[39mappend(model_predictions[diff_col])\n\u001b[1;32m     40\u001b[0m     feature_names\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDifference (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshadow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - target)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/media/emanuel/sdd_sata/projetos/projeto_mestrado_ofc/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/media/emanuel/sdd_sata/projetos/projeto_mestrado_ofc/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'target'"
     ]
    }
   ],
   "source": [
    "# First, modify the attack model to accept the difference features\n",
    "def create_attack_model_with_differences(num_shadow_models):\n",
    "    \"\"\"Creates attack model that accepts differences between models as features\"\"\"\n",
    "    num_features = num_shadow_models  # number of differences (each shadow model vs target)\n",
    "    \n",
    "    model_attack = Sequential([\n",
    "        # Input shape matches number of difference features\n",
    "        Dense(5, input_shape=(num_features,), activation='sigmoid', name='hidden'),\n",
    "        Dense(1, activation='sigmoid', name='output')\n",
    "    ])\n",
    "    \n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001, decay=1e-7)\n",
    "    model_attack.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    return model_attack\n",
    "\n",
    "# Create the difference features for training data\n",
    "def create_difference_features(predictions_df, is_training=True):\n",
    "    \"\"\"Creates features based on differences between model predictions\"\"\"\n",
    "    # Pivot the predictions to get one column per model\n",
    "    model_predictions = pd.pivot_table(\n",
    "        predictions_df,\n",
    "        values='prediction',\n",
    "        index='sample_index',\n",
    "        columns='model_name',\n",
    "        aggfunc='first'\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Calculate differences between target and each shadow model\n",
    "    difference_features = []\n",
    "    feature_names = []\n",
    "    \n",
    "    # Get all shadow model names\n",
    "    shadow_models = [col for col in model_predictions.columns if 'shadow' in col]\n",
    "    \n",
    "    for shadow in shadow_models:\n",
    "        diff_col = f'diff_{shadow}_target'\n",
    "        model_predictions[diff_col] = model_predictions[shadow] - model_predictions['target']\n",
    "        difference_features.append(model_predictions[diff_col])\n",
    "        feature_names.append(f'Difference ({shadow} - target)')\n",
    "    \n",
    "    # Stack differences into a numpy array\n",
    "    X_diff = np.column_stack(difference_features)\n",
    "    \n",
    "    return X_diff, feature_names\n",
    "\n",
    "# Create training and test datasets with differences\n",
    "X_train_diff, feature_names = create_difference_features(train_set_df, is_training=True)\n",
    "X_test_diff, _ = create_difference_features(test_set_df, is_training=False)\n",
    "\n",
    "# Create and train the modified attack model\n",
    "num_shadow_models = 5  # adjust based on your ns value\n",
    "model_attack = create_attack_model_with_differences(num_shadow_models)\n",
    "\n",
    "# Train the model with the difference features\n",
    "hist_attack = model_attack.fit(\n",
    "    X_train_diff, ytr_att,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test_diff, yts_att_combined),\n",
    "    shuffle=True,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Now create SHAP explainer with the difference features\n",
    "explainer = shap.Explainer(model_attack, X_train_diff[:1000])  # Use subset for efficiency\n",
    "shap_values = explainer(X_test_diff)\n",
    "\n",
    "# Plot SHAP summary\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(\n",
    "    shap_values, \n",
    "    X_test_diff,\n",
    "    feature_names=feature_names,\n",
    "    show=False\n",
    ")\n",
    "plt.title(\"SHAP Values for Model Differences\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create detailed analysis of SHAP values\n",
    "def analyze_shap_by_membership(shap_values, X_diff, test_set_df, feature_names):\n",
    "    \"\"\"Analyzes SHAP values separately for members and non-members\"\"\"\n",
    "    # Create DataFrame with SHAP values and metadata\n",
    "    shap_df = pd.DataFrame(shap_values.values, columns=feature_names)\n",
    "    shap_df['is_member'] = test_set_df['is_member']\n",
    "    \n",
    "    # Calculate average absolute SHAP values\n",
    "    print(\"\\nAverage absolute SHAP values:\")\n",
    "    print(\"\\nFor members:\")\n",
    "    print(shap_df[shap_df['is_member'] == 0][feature_names].abs().mean())\n",
    "    print(\"\\nFor non-members:\")\n",
    "    print(shap_df[shap_df['is_member'] == 1][feature_names].abs().mean())\n",
    "    \n",
    "    # Create separate plots for members and non-members\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Members\n",
    "    member_mask = test_set_df['is_member'] == 0\n",
    "    shap.summary_plot(\n",
    "        shap_values[member_mask],\n",
    "        X_diff[member_mask],\n",
    "        feature_names=feature_names,\n",
    "        ax=ax1,\n",
    "        show=False\n",
    "    )\n",
    "    ax1.set_title(\"SHAP Values for Members\")\n",
    "    \n",
    "    # Non-members\n",
    "    non_member_mask = test_set_df['is_member'] == 1\n",
    "    shap.summary_plot(\n",
    "        shap_values[non_member_mask],\n",
    "        X_diff[non_member_mask],\n",
    "        feature_names=feature_names,\n",
    "        ax=ax2,\n",
    "        show=False\n",
    "    )\n",
    "    ax2.set_title(\"SHAP Values for Non-members\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run the analysis\n",
    "analyze_shap_by_membership(shap_values, X_test_diff, test_set_df, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rastreando conjunto de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_83135/1336513710.py:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  'prediction': float(shadow_tr_preds[idx]),\n",
      "/tmp/ipykernel_83135/1336513710.py:26: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  'prediction': float(shadow_ts_preds[idx]),\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272us/step\n"
     ]
    }
   ],
   "source": [
    "# First, create structured data for training set\n",
    "train_set_data = []\n",
    "\n",
    "# Track data for each shadow model\n",
    "for i in np.arange(ns):\n",
    "    model_shadow = load_model(f'UCI_Adult_shadow_{data_size}_{i}.h5')\n",
    "    \n",
    "    # Get predictions from shadow model on its train and test data\n",
    "    shadow_tr_preds = model_shadow.predict(xtr_shadow)\n",
    "    shadow_ts_preds = model_shadow.predict(xts_shadow)\n",
    "    \n",
    "    # Add training samples (members)\n",
    "    for idx in range(len(shadow_tr_preds)):\n",
    "        train_set_data.append({\n",
    "            'prediction': float(shadow_tr_preds[idx]),\n",
    "            'is_member': 0,  # member of training set\n",
    "            'true_label': int(ytr_shadow[idx]),\n",
    "            'model_name': f'shadow_{i}',\n",
    "            'sample_index': idx,\n",
    "            'data_split': 'train'\n",
    "        })\n",
    "    \n",
    "    # Add test samples (non-members)\n",
    "    for idx in range(len(shadow_ts_preds)):\n",
    "        train_set_data.append({\n",
    "            'prediction': float(shadow_ts_preds[idx]),\n",
    "            'is_member': 1,  # non-member (test set)\n",
    "            'true_label': int(yts_shadow[idx]),\n",
    "            'model_name': f'shadow_{i}',\n",
    "            'sample_index': idx,\n",
    "            'data_split': 'test'\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "train_set_df = pd.DataFrame(train_set_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>is_member</th>\n",
       "      <th>true_label</th>\n",
       "      <th>model_name</th>\n",
       "      <th>sample_index</th>\n",
       "      <th>data_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.504088</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.298486</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>shadow_0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.827214</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>shadow_0</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014987</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_0</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.526238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_0</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0.010776</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_4</td>\n",
       "      <td>9995</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0.362464</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>shadow_4</td>\n",
       "      <td>9996</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0.710084</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_4</td>\n",
       "      <td>9997</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0.729532</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>shadow_4</td>\n",
       "      <td>9998</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0.002955</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_4</td>\n",
       "      <td>9999</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       prediction  is_member  true_label model_name  sample_index data_split\n",
       "0        0.504088          0           0   shadow_0             0      train\n",
       "1        0.298486          0           1   shadow_0             1      train\n",
       "2        0.827214          0           1   shadow_0             2      train\n",
       "3        0.014987          0           0   shadow_0             3      train\n",
       "4        0.526238          0           0   shadow_0             4      train\n",
       "...           ...        ...         ...        ...           ...        ...\n",
       "99995    0.010776          1           0   shadow_4          9995       test\n",
       "99996    0.362464          1           1   shadow_4          9996       test\n",
       "99997    0.710084          1           0   shadow_4          9997       test\n",
       "99998    0.729532          1           1   shadow_4          9998       test\n",
       "99999    0.002955          1           0   shadow_4          9999       test\n",
       "\n",
       "[100000 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/emanuel/sdd_sata/projetos/projeto_mestrado_ofc/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/media/emanuel/sdd_sata/projetos/projeto_mestrado_ofc/.venv/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 20000\n'y' sizes: 100000\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m model_attack\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mopt, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Train the model with the difference features\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m hist_attack \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_attack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_diff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mis_member\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_diff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_set_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mis_member\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     58\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Create SHAP explainer with the difference features\u001b[39;00m\n\u001b[1;32m     61\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mExplainer(model_attack, X_train_diff[:\u001b[38;5;241m1000\u001b[39m])\n",
      "File \u001b[0;32m/media/emanuel/sdd_sata/projetos/projeto_mestrado_ofc/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/media/emanuel/sdd_sata/projetos/projeto_mestrado_ofc/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/data_adapter_utils.py:115\u001b[0m, in \u001b[0;36mcheck_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    111\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[1;32m    113\u001b[0m     )\n\u001b[1;32m    114\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 20000\n'y' sizes: 100000\n"
     ]
    }
   ],
   "source": [
    "# Create the difference features for both training and test sets\n",
    "def create_model_differences_dataset(df):\n",
    "    \"\"\"Creates features based on differences between model predictions\"\"\"\n",
    "    # Pivot the predictions to get one column per model\n",
    "    model_predictions = pd.pivot_table(\n",
    "        df,\n",
    "        values='prediction',\n",
    "        index=['sample_index', 'data_split'],\n",
    "        columns='model_name',\n",
    "        aggfunc='first'\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Get reference shadow model (first one)\n",
    "    reference_model = [col for col in model_predictions.columns if 'shadow_0' in col][0]\n",
    "    \n",
    "    # Calculate differences between shadow models\n",
    "    difference_features = []\n",
    "    feature_names = []\n",
    "    \n",
    "    # Get all shadow model names except the reference\n",
    "    shadow_models = [col for col in model_predictions.columns \n",
    "                    if 'shadow' in col and col != reference_model]\n",
    "    \n",
    "    # Calculate differences between shadow models\n",
    "    for shadow in shadow_models:\n",
    "        diff_col = f'diff_{shadow}_{reference_model}'\n",
    "        model_predictions[diff_col] = model_predictions[shadow] - model_predictions[reference_model]\n",
    "        difference_features.append(model_predictions[diff_col])\n",
    "        feature_names.append(f'Difference ({shadow} - {reference_model})')\n",
    "    \n",
    "    # Stack differences into a numpy array\n",
    "    X_diff = np.column_stack(difference_features)\n",
    "    \n",
    "    return X_diff, feature_names\n",
    "\n",
    "# Create difference features for training and test sets\n",
    "X_train_diff, feature_names = create_model_differences_dataset(train_set_df)\n",
    "X_test_diff, _ = create_model_differences_dataset(test_set_df)\n",
    "\n",
    "# Create and train the modified attack model\n",
    "num_differences = len(feature_names)  # number of difference features\n",
    "model_attack = Sequential([\n",
    "    Dense(5, input_shape=(num_differences,), activation='sigmoid', name='hidden'),\n",
    "    Dense(1, activation='sigmoid', name='output')\n",
    "])\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001, decay=1e-7)\n",
    "model_attack.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# Train the model with the difference features\n",
    "hist_attack = model_attack.fit(\n",
    "    X_train_diff, train_set_df['is_member'].values,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test_diff, test_set_df['is_member'].values),\n",
    "    shuffle=True,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Create SHAP explainer with the difference features\n",
    "explainer = shap.Explainer(model_attack, X_train_diff[:1000])\n",
    "shap_values = explainer(X_test_diff)\n",
    "\n",
    "# Plot SHAP summary\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(\n",
    "    shap_values, \n",
    "    X_test_diff,\n",
    "    feature_names=feature_names,\n",
    "    show=False\n",
    ")\n",
    "plt.title(\"SHAP Values for Model Differences\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the complete tracked datasets\n",
    "tracking_data = {\n",
    "    'train_set': train_set_df,\n",
    "    'test_set': test_set_df,\n",
    "    'X_train_diff': X_train_diff,\n",
    "    'X_test_diff': X_test_diff,\n",
    "    'feature_names': feature_names,\n",
    "    'shap_values': shap_values.values\n",
    "}\n",
    "np.save(f'./mia_tracking_data_{data_size}.npy', tracking_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>is_member</th>\n",
       "      <th>true_label</th>\n",
       "      <th>model_name</th>\n",
       "      <th>sample_index</th>\n",
       "      <th>data_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.504088</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.298486</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>shadow_0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.827214</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>shadow_0</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014987</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_0</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.526238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_0</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0.010776</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_4</td>\n",
       "      <td>9995</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0.362464</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>shadow_4</td>\n",
       "      <td>9996</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0.710084</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_4</td>\n",
       "      <td>9997</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0.729532</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>shadow_4</td>\n",
       "      <td>9998</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0.002955</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>shadow_4</td>\n",
       "      <td>9999</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       prediction  is_member  true_label model_name  sample_index data_split\n",
       "0        0.504088          0           0   shadow_0             0      train\n",
       "1        0.298486          0           1   shadow_0             1      train\n",
       "2        0.827214          0           1   shadow_0             2      train\n",
       "3        0.014987          0           0   shadow_0             3      train\n",
       "4        0.526238          0           0   shadow_0             4      train\n",
       "...           ...        ...         ...        ...           ...        ...\n",
       "99995    0.010776          1           0   shadow_4          9995       test\n",
       "99996    0.362464          1           1   shadow_4          9996       test\n",
       "99997    0.710084          1           0   shadow_4          9997       test\n",
       "99998    0.729532          1           1   shadow_4          9998       test\n",
       "99999    0.002955          1           0   shadow_4          9999       test\n",
       "\n",
       "[100000 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of xtr_att: (100000, 1)\n",
      "Shape of ytr_att: (100000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_83135/3721421044.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  'prediction': float(model_preds[idx]),\n",
      "/tmp/ipykernel_83135/3721421044.py:22: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  'is_member': float(model_labels[idx]),\n",
      "/tmp/ipykernel_83135/3721421044.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  'prediction': float(model_preds[data_size + idx]),\n",
      "/tmp/ipykernel_83135/3721421044.py:33: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  'is_member': float(model_labels[data_size + idx]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in train_set_df: 100000\n",
      "Shape of X_train_diff: (20000, 4)\n",
      "Shape of training labels: (100000,)\n",
      "Shape of X_test_diff: (20000, 4)\n",
      "Shape of test labels: (30000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/emanuel/sdd_sata/projetos/projeto_mestrado_ofc/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/media/emanuel/sdd_sata/projetos/projeto_mestrado_ofc/.venv/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 20000\n'y' sizes: 100000\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 100\u001b[0m\n\u001b[1;32m     97\u001b[0m model_attack\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mopt, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Train the model with the difference features\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m hist_attack \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_attack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_diff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mis_member\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_diff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_set_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mis_member\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m    107\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/emanuel/sdd_sata/projetos/projeto_mestrado_ofc/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/media/emanuel/sdd_sata/projetos/projeto_mestrado_ofc/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/data_adapter_utils.py:115\u001b[0m, in \u001b[0;36mcheck_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    111\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[1;32m    113\u001b[0m     )\n\u001b[1;32m    114\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 20000\n'y' sizes: 100000\n"
     ]
    }
   ],
   "source": [
    "# Print shapes to debug\n",
    "print(\"Shape of xtr_att:\", xtr_att.shape)\n",
    "print(\"Shape of ytr_att:\", ytr_att.shape)\n",
    "\n",
    "# First, create structured data for training set with correct shapes\n",
    "train_set_data = []\n",
    "\n",
    "# Track data for each shadow model\n",
    "for i in np.arange(ns):\n",
    "    start_idx = i * 2 * data_size\n",
    "    end_idx = (i + 1) * 2 * data_size\n",
    "    \n",
    "    # Get the predictions and labels for this shadow model\n",
    "    model_preds = xtr_att[start_idx:end_idx]\n",
    "    model_labels = ytr_att[start_idx:end_idx]\n",
    "    true_labels = xtr_att_truelabels[start_idx:end_idx]\n",
    "    \n",
    "    # First half is training data (members)\n",
    "    for idx in range(data_size):\n",
    "        train_set_data.append({\n",
    "            'prediction': float(model_preds[idx]),\n",
    "            'is_member': float(model_labels[idx]),\n",
    "            'true_label': int(true_labels[idx]),\n",
    "            'model_name': f'shadow_{i}',\n",
    "            'sample_index': idx,\n",
    "            'data_split': 'train'\n",
    "        })\n",
    "    \n",
    "    # Second half is test data (non-members)\n",
    "    for idx in range(data_size):\n",
    "        train_set_data.append({\n",
    "            'prediction': float(model_preds[data_size + idx]),\n",
    "            'is_member': float(model_labels[data_size + idx]),\n",
    "            'true_label': int(true_labels[data_size + idx]),\n",
    "            'model_name': f'shadow_{i}',\n",
    "            'sample_index': idx,\n",
    "            'data_split': 'test'\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "train_set_df = pd.DataFrame(train_set_data)\n",
    "\n",
    "print(\"Number of samples in train_set_df:\", len(train_set_df))\n",
    "\n",
    "# Create the difference features for both training and test sets\n",
    "def create_model_differences_dataset(df):\n",
    "    \"\"\"Creates features based on differences between model predictions\"\"\"\n",
    "    # Pivot the predictions to get one column per model\n",
    "    model_predictions = pd.pivot_table(\n",
    "        df,\n",
    "        values='prediction',\n",
    "        index=['sample_index', 'data_split'],\n",
    "        columns='model_name',\n",
    "        aggfunc='first'\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Get reference shadow model (first one)\n",
    "    reference_model = [col for col in model_predictions.columns if 'shadow_0' in col][0]\n",
    "    \n",
    "    # Calculate differences between shadow models\n",
    "    difference_features = []\n",
    "    feature_names = []\n",
    "    \n",
    "    # Get all shadow model names except the reference\n",
    "    shadow_models = [col for col in model_predictions.columns \n",
    "                    if 'shadow' in col and col != reference_model]\n",
    "    \n",
    "    # Calculate differences between shadow models\n",
    "    for shadow in shadow_models:\n",
    "        diff_col = f'diff_{shadow}_{reference_model}'\n",
    "        model_predictions[diff_col] = model_predictions[shadow] - model_predictions[reference_model]\n",
    "        difference_features.append(model_predictions[diff_col])\n",
    "        feature_names.append(f'Difference ({shadow} - {reference_model})')\n",
    "    \n",
    "    # Stack differences into a numpy array\n",
    "    X_diff = np.column_stack(difference_features)\n",
    "    \n",
    "    return X_diff, feature_names, model_predictions\n",
    "\n",
    "# Create difference features for training and test sets\n",
    "X_train_diff, feature_names, train_predictions = create_model_differences_dataset(train_set_df)\n",
    "X_test_diff, _, test_predictions = create_model_differences_dataset(test_set_df)\n",
    "\n",
    "print(\"Shape of X_train_diff:\", X_train_diff.shape)\n",
    "print(\"Shape of training labels:\", train_set_df['is_member'].values.shape)\n",
    "print(\"Shape of X_test_diff:\", X_test_diff.shape)\n",
    "print(\"Shape of test labels:\", test_set_df['is_member'].values.shape)\n",
    "\n",
    "# Create and train the modified attack model\n",
    "num_differences = len(feature_names)  # number of difference features\n",
    "model_attack = Sequential([\n",
    "    Dense(5, input_shape=(num_differences,), activation='sigmoid', name='hidden'),\n",
    "    Dense(1, activation='sigmoid', name='output')\n",
    "])\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001, decay=1e-7)\n",
    "model_attack.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# Train the model with the difference features\n",
    "hist_attack = model_attack.fit(\n",
    "    X_train_diff, train_set_df['is_member'].values,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test_diff, test_set_df['is_member'].values),\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shape of xtr_att: (100000, 1)\n",
    "Shape of ytr_att: (100000, 1)\n",
    "Number of samples in train_set_df: 100000\n",
    "Shape of X_train_diff: (20000, 4)\n",
    "Shape of training labels: (100000,)\n",
    "Shape of X_test_diff: (20000, 4)\n",
    "Shape of test labels: (30000,)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
